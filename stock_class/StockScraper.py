# ğŸ”¥ å®Œæ•´çš„ç€è¦½å™¨è·¯å¾‘åµæ¸¬é‚è¼¯
# è¤‡è£½æ­¤å‡½æ•¸æ›¿æ› StockScraper.py ä¸­çš„ setup_playwright_path()

import sys
import os


def setup_playwright_path():
    """
    è¨­å®š Playwright ç€è¦½å™¨è·¯å¾‘

    åµæ¸¬å„ªå…ˆé †åºï¼š
    1. æ‰“åŒ…å¾Œçš„ç›¸å°è·¯å¾‘ï¼ˆèˆ‡ .exe åŒå±¤çš„ ms-playwrightï¼‰
    2. PyInstaller çš„è‡¨æ™‚è³‡æ–™å¤¾ï¼ˆ_MEIPASSï¼‰
    3. é–‹ç™¼ç’°å¢ƒçš„ AppData è·¯å¾‘
    """

    # ğŸ”¥ æ–¹æ³• 1ï¼šæª¢æŸ¥æ˜¯å¦åœ¨æ‰“åŒ…ç’°å¢ƒä¸­ï¼ˆæœ€å„ªå…ˆï¼‰
    if getattr(sys, 'frozen', False):
        # æ‰“åŒ…å¾Œçš„è·¯å¾‘ï¼ˆ.exe æ‰€åœ¨ç›®éŒ„ï¼‰
        base_path = os.path.dirname(sys.executable)

        # æª¢æŸ¥èˆ‡ .exe åŒå±¤çš„ ms-playwright è³‡æ–™å¤¾
        relative_browser_path = os.path.join(base_path, 'ms-playwright')

        if os.path.exists(relative_browser_path):
            os.environ['PLAYWRIGHT_BROWSERS_PATH'] = relative_browser_path
            print(f"âœ“ ä½¿ç”¨æ‰“åŒ…çš„ç€è¦½å™¨: {relative_browser_path}")

            # é©—è­‰ Chromium æ˜¯å¦å­˜åœ¨
            chromium_path = os.path.join(relative_browser_path, 'chromium-1187', 'chrome-win', 'chrome.exe')
            if os.path.exists(chromium_path):
                print(f"âœ“ Chromium é©—è­‰é€šé: {chromium_path}")
            else:
                print(f"âš ï¸ è­¦å‘Šï¼šChromium åŸ·è¡Œæª”ä¸å­˜åœ¨æ–¼é æœŸä½ç½®")
                print(f"   é æœŸä½ç½®: {chromium_path}")

            return

        # ğŸ”¥ æ–¹æ³• 2ï¼šæª¢æŸ¥ PyInstaller çš„è‡¨æ™‚è§£å£“ç¸®è³‡æ–™å¤¾
        if hasattr(sys, '_MEIPASS'):
            meipass_browser_path = os.path.join(sys._MEIPASS, 'ms-playwright')

            if os.path.exists(meipass_browser_path):
                os.environ['PLAYWRIGHT_BROWSERS_PATH'] = meipass_browser_path
                print(f"âœ“ ä½¿ç”¨ _MEIPASS ç€è¦½å™¨: {meipass_browser_path}")
                return

        # å¦‚æœæ‰“åŒ…ç’°å¢ƒæ‰¾ä¸åˆ°ï¼Œè­¦å‘Šä½¿ç”¨è€…
        print("âš ï¸ è­¦å‘Šï¼šæ‰“åŒ…ç’°å¢ƒä¸­æ‰¾ä¸åˆ° ms-playwright è³‡æ–™å¤¾")
        print("   ç¨‹å¼å¯èƒ½ç„¡æ³•æ­£å¸¸é‹è¡Œï¼Œè«‹ç¢ºèªä»¥ä¸‹è·¯å¾‘æ˜¯å¦å­˜åœ¨ï¼š")
        print(f"   1. {relative_browser_path}")

    # ğŸ”¥ æ–¹æ³• 3ï¼šé–‹ç™¼ç’°å¢ƒçš„ AppData è·¯å¾‘ï¼ˆåƒ…ä¾›é–‹ç™¼æ™‚ä½¿ç”¨ï¼‰
    else:
        appdata_browser_path = os.path.join(
            os.path.expanduser('~'),
            'AppData',
            'Local',
            'ms-playwright'
        )

        if os.path.exists(appdata_browser_path):
            os.environ['PLAYWRIGHT_BROWSERS_PATH'] = appdata_browser_path
            print(f"âœ“ é–‹ç™¼ç’°å¢ƒï¼šä½¿ç”¨ AppData ç€è¦½å™¨")
            print(f"   è·¯å¾‘: {appdata_browser_path}")
        else:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° Playwright ç€è¦½å™¨")
            print("   è«‹åŸ·è¡Œï¼šplaywright install chromium")


# åœ¨æ¨¡çµ„è¼‰å…¥æ™‚ç«‹å³è¨­å®š
setup_playwright_path()

# ç¾åœ¨æ‰å°å…¥ playwright å’Œå…¶ä»–æ¨¡çµ„
import asyncio
import pandas as pd
import random
from io import StringIO
from bs4 import BeautifulSoup
import json
import re
import schwabdev

# è‡ªå®šç¾©ç•°å¸¸é¡åˆ¥
class TokenExpiredException(Exception):
    """Token éæœŸç•°å¸¸"""
    pass


class StockScraper:
    def __init__(self, stocks, config=None, headless=True, max_concurrent=15):
        """
        åˆå§‹åŒ–çˆ¬èŸ²é¡åˆ¥ã€‚
        """
        self.stocks = stocks.get('final_stocks')
        self.us_stocks = stocks.get('us_stocks')
        self.non_us_stocks = stocks.get('non_us_stocks')

        # ğŸ”¥ æ–°å¢ï¼šcoe_stocks å’Œ adr_stocks
        self.coe_stocks = stocks.get('coe_stocks', [])
        self.adr_stocks = stocks.get('adr_stocks', [])

        self.config = config
        self.headless = headless
        self.max_concurrent = max_concurrent
        self.browser = None
        self.playwright = None
        self.contexts = []
        self.contexts_lock = asyncio.Lock()
        self._validate_schwab_config()

        # ğŸ”¥ é—œéµä¿®æ”¹ï¼šSchwab Client é‡ç”¨
        self.schwab_client = None
        self.schwab_client_lock = asyncio.Lock()

        # ğŸ”¥ æ–°å¢ï¼šäº¤æ˜“æ‰€è³‡è¨Šï¼ˆä¾› TradingView ä½¿ç”¨ï¼‰
        self.stock_exchanges = {}  # {stock: 'NYSE'} - ç”± StockManager è¨­å®š

        # ğŸ”¥ æ–°å¢ï¼šç«‹å³åˆå§‹åŒ– Schwab Clientï¼ˆç”¨æ–¼é©—è­‰éšæ®µï¼‰
        if self.schwab_available:
            try:
                self.initialize_schwab_client()
                print("âœ… Schwab Client å·²åœ¨åˆå§‹åŒ–éšæ®µæº–å‚™å°±ç·’")
            except Exception as e:
                print(f"âš ï¸ Schwab Client åˆå§‹åŒ–å¤±æ•—: {e}")
                print("   é©—è­‰åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
                self.schwab_available = False

    # åœ¨ StockScraper é¡åˆ¥ä¸­ï¼Œåªéœ€è¦ä¿®æ”¹ initialize_schwab_client æ–¹æ³•

    def initialize_schwab_client(self):
        """
        åˆå§‹åŒ– Schwab Clientï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰- æ”¯æ´ 3.0.0 .db æ ¼å¼

        âš ï¸ æ³¨æ„ï¼šæ­¤æ–¹æ³•ç¾åœ¨æœƒåœ¨ __init__ æ™‚ç«‹å³åŸ·è¡Œï¼Œ
                 ç¢ºä¿é©—è­‰éšæ®µå¯ä»¥ä½¿ç”¨ schwab_client
        """
        if self.schwab_client is not None:
            return  # å·²åˆå§‹åŒ–ï¼Œè·³é

        if not self.schwab_available or not self.config:
            raise ValueError("Schwab API é…ç½®æœªè¨­å®š")

        print("ğŸ”§ åˆå§‹åŒ– Schwab API Client...")

        # è¨ˆç®—è·¯å¾‘
        if getattr(sys, 'frozen', False):
            base_path = os.path.dirname(sys.executable)
        else:
            current_file = os.path.abspath(__file__)
            project_root = os.path.dirname(os.path.dirname(current_file))
            base_path = os.path.join(project_root, 'schwab')

        # ğŸ”¥ é—œéµä¿®æ­£ï¼šå®Œæ•´çš„ tokens.db æª”æ¡ˆè·¯å¾‘
        tokens_file_path = os.path.join(base_path, 'tokens.db')

        print(f"ğŸ“ Token DB è·¯å¾‘: {tokens_file_path}")
        print(f"ğŸ“ æª”æ¡ˆæ˜¯å¦å­˜åœ¨: {os.path.exists(tokens_file_path)}")

        # ğŸ”¥ ä½¿ç”¨æ­£ç¢ºçš„åƒæ•¸ï¼štokens_db (å®Œæ•´æª”æ¡ˆè·¯å¾‘)
        self.schwab_client = schwabdev.Client(
            self.config['app_key'],
            self.config['app_secret'],
            callback_url="https://127.0.0.1",
            tokens_db=tokens_file_path,
            timeout=30
        )

        print("âœ… Schwab Client å·²åˆå§‹åŒ–ï¼ˆå¯ç”¨æ–¼é©—è­‰å’Œé¸æ“‡æ¬Šéˆï¼‰")

    def _validate_schwab_config(self):
        """é©—è­‰ Schwab API é…ç½®æ˜¯å¦å®Œæ•´"""
        if self.config is None:
            print("âš ï¸ è­¦å‘Šï¼šæœªæä¾› Schwab API é…ç½®")
            print("é¸æ“‡æ¬ŠéˆåŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            self.schwab_available = False
            return

        required_keys = ['app_key', 'app_secret']
        missing_keys = [key for key in required_keys if not self.config.get(key)]

        if missing_keys:
            print(f"âš ï¸ è­¦å‘Šï¼šSchwab API é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘ï¼š{', '.join(missing_keys)}")
            print("é¸æ“‡æ¬ŠéˆåŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            self.schwab_available = False
        else:
            print("âœ“ Schwab API é…ç½®å·²è¼‰å…¥")
            self.schwab_available = True

    async def setup_browser(self):
        """å•Ÿå‹•ç€è¦½å™¨ï¼ˆåŠ å…¥ååµæ¸¬ï¼‰- è‡ªå‹•åµæ¸¬è¢å¹•ä¸¦ç½®ä¸­"""
        print("ğŸ”§ æ­£åœ¨å•Ÿå‹• Playwright...")
        from playwright.async_api import async_playwright

        self.playwright = await async_playwright().start()

        print(f"ğŸ”§ æ­£åœ¨å•Ÿå‹• Chromiumï¼ˆ{'ç„¡é ­' if self.headless else 'æœ‰é ­'}æ¨¡å¼ï¼Œååµæ¸¬ï¼‰...")

        # ğŸ”¥ åŸºç¤åƒæ•¸ï¼ˆheadless å’Œ æœ‰é ­æ¨¡å¼éƒ½éœ€è¦ï¼‰
        base_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-dev-shm-usage',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
            '--no-sandbox',
            '--disable-setuid-sandbox',
            '--disable-infobars',
            '--ignore-certifcate-errors',
            '--ignore-certifcate-errors-spki-list',
        ]

        # ğŸ”¥ æ ¹æ“š headless ç‹€æ…‹æ±ºå®šæ˜¯å¦æ·»åŠ è¦–çª—åƒæ•¸
        if not self.headless:
            # åªæœ‰åœ¨æœ‰é ­æ¨¡å¼æ‰è™•ç†è¦–çª—ä½ç½®
            try:
                from screeninfo import get_monitors
                monitors = get_monitors()
                primary_monitor = next((m for m in monitors if m.is_primary), monitors[0])

                screen_width = primary_monitor.width
                screen_height = primary_monitor.height
                x_offset = primary_monitor.x
                y_offset = primary_monitor.y

                print(f"ğŸ“º åµæ¸¬åˆ°ä¸»è¢å¹•è§£æåº¦: {screen_width}x{screen_height} (åç§»: {x_offset}, {y_offset})")
                print(f"ğŸ“º å…± {len(monitors)} å€‹è¢å¹•")

            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•åµæ¸¬è¢å¹•è§£æåº¦ï¼Œä½¿ç”¨é è¨­å€¼: {e}")
                screen_width = 1920
                screen_height = 1080
                x_offset = 0
                y_offset = 0

            # è¨­å®šè¦–çª—å¤§å°
            window_width = int(screen_width * 0.8)
            window_height = int(screen_height * 0.85)
            x_position = x_offset + (screen_width - window_width) // 2
            y_position = y_offset + (screen_height - window_height) // 2

            print(f"ğŸªŸ ç€è¦½å™¨è¦–çª—: {window_width}x{window_height} (ä½ç½®: {x_position},{y_position})")

            # æ·»åŠ è¦–çª—ç›¸é—œåƒæ•¸
            base_args.append('--start-maximized')
        else:
            # ç„¡é ­æ¨¡å¼ï¼šä¸æ·»åŠ ä»»ä½•è¦–çª—åƒæ•¸
            print("ğŸ‘» ç„¡é ­æ¨¡å¼ï¼šç€è¦½å™¨å°‡åœ¨èƒŒæ™¯åŸ·è¡Œ")

        self.browser = await self.playwright.chromium.launch(
            headless=self.headless,
            args=base_args
        )

        if self.headless:
            print("âœ… ç€è¦½å™¨å•Ÿå‹•æˆåŠŸï¼ˆç„¡é ­æ¨¡å¼ï¼‰")
        else:
            print("âœ… ç€è¦½å™¨å•Ÿå‹•æˆåŠŸï¼ˆè¦–çª—å·²ç½®ä¸­ï¼‰")

    async def cleanup(self):
        """æ¸…ç†è³‡æº - ç¢ºä¿ Playwright å­é€²ç¨‹å®Œå…¨é—œé–‰"""
        import asyncio

        print("ğŸ§¹ é–‹å§‹æ¸…ç† StockScraper è³‡æº...")

        try:
            # Step 1: é—œé–‰æ‰€æœ‰ contexts
            if hasattr(self, 'contexts') and self.contexts:
                print(f"ğŸ§¹ é—œé–‰ {len(self.contexts)} å€‹æœªé—œé–‰çš„ context...")
                contexts_to_close = list(self.contexts)

                for context in contexts_to_close:
                    try:
                        await asyncio.wait_for(context.close(), timeout=2.0)
                    except Exception as e:
                        print(f"âš ï¸ Context é—œé–‰éŒ¯èª¤: {e}")

                self.contexts.clear()
                print("âœ… æ‰€æœ‰ context å·²é—œé–‰")

            # Step 2: é—œé–‰ç€è¦½å™¨
            if self.browser:
                print("ğŸ§¹ é—œé–‰ Playwright ç€è¦½å™¨...")
                try:
                    await asyncio.wait_for(self.browser.close(), timeout=3.0)
                    print("âœ… ç€è¦½å™¨å·²é—œé–‰")
                except Exception as e:
                    print(f"âš ï¸ ç€è¦½å™¨é—œé–‰éŒ¯èª¤: {e}")
                finally:
                    self.browser = None

            # Step 3: åœæ­¢ Playwright
            if self.playwright:
                print("ğŸ§¹ åœæ­¢ Playwright...")
                try:
                    await asyncio.wait_for(self.playwright.stop(), timeout=3.0)
                    print("âœ… Playwright å·²åœæ­¢")
                except Exception as e:
                    print(f"âš ï¸ Playwright åœæ­¢éŒ¯èª¤: {e}")
                finally:
                    self.playwright = None

            # ğŸ”¥ Step 4: é—œéµï¼ç­‰å¾…å­é€²ç¨‹å®Œå…¨çµæŸ
            print("ğŸ§¹ ç­‰å¾…å­é€²ç¨‹å®Œå…¨çµæŸ...")
            await asyncio.sleep(1.0)  # çµ¦ 1 ç§’è®“å­é€²ç¨‹æ¸…ç†
            print("âœ… å­é€²ç¨‹æ¸…ç†å®Œæˆ")

            # Step 5: æ¸…ç† Schwab Client
            if self.schwab_client:
                self.schwab_client = None

            print("âœ… StockScraper è³‡æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            print(f"âŒ æ¸…ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            # ç¢ºä¿è®Šæ•¸è¢«é‡ç½®
            self.browser = None
            self.playwright = None
            self.schwab_client = None
            if hasattr(self, 'contexts'):
                self.contexts.clear()

    async def fetch_financials_data(self, stock, semaphore):
        """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„æ•¸æ“šï¼ˆfinancialsï¼‰ã€‚"""
        async with semaphore:
            context = None  # ğŸ”¥ åˆå§‹åŒ–
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                    viewport={"width": 800, "height": 600},
                    java_script_enabled=True
                )
                # ğŸ”¥ è¿½è¹¤ context
                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page_financials = await context.new_page()
                    financials = await asyncio.gather(self.get_financials(stock, page_financials))
                    return {stock: financials}
                finally:
                    await context.close()
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                # ç¢ºä¿ context è¢«é—œé–‰
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {"stock": stock, "error": str(e)}

    async def get_financials(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„è²¡å‹™è³‡æ–™ä¸¦å›å‚³ DataFrameã€‚"""
        URL = f'https://www.roic.ai/quote/{stock}/financials'
        attempt = 0

        while attempt < retries:
            try:
                await asyncio.sleep(random.uniform(1, 3))
                await page.goto(URL, wait_until='networkidle', timeout=100000) # networkidle

                # 2025/09/23 æ›´æ–°æ–°é‚è¼¯
                # await page.wait_for_selector('table.w-full.caption-bottom.text-sm.table-fixed', timeout=100000)
                # content = await page.content()
                # dfs = pd.read_html(StringIO(content))
                # return dfs

                # ä¹‹å‰çš„é‚è¼¯
                if await page.query_selector(
                        'div.rounded-lg.bg-card.text-card-foreground.shadow-sm.mx-auto.flex.w-\\[500px\\].flex-col.items-center.border.drop-shadow-lg'):
                    return f'{stock}æ˜¯éç¾åœ‹ä¼æ¥­ï¼Œæ­¤é é¢é ˆä»˜è²»ï¼'
                else:
                    await page.wait_for_selector('table.w-full.caption-bottom.text-sm.table-fixed', timeout=100000)
                    content = await page.content()
                    dfs = pd.read_html(StringIO(content))
                    return dfs

            except Exception as e:
                attempt += 1
                if attempt == retries:
                    return f"Error for {stock}: {e}"

        return f"Failed to retrieve data for {stock}"

    async def run_financial(self):
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_financials_data(stock, semaphore) for stock in self.us_stocks]
            result = await asyncio.gather(*tasks)
        finally:
            await self.cleanup()
        return result

    async def fetch_ratios_data(self, stock, semaphore):
        """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„æ•¸æ“šï¼ˆRatiosï¼‰ã€‚"""
        async with semaphore:
            context = None  # ğŸ”¥ åˆå§‹åŒ–
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                    viewport={"width": 800, "height": 600},
                    java_script_enabled=True
                )
                # ğŸ”¥ è¿½è¹¤ context
                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page_ratios = await context.new_page()
                    ratios = await asyncio.gather(self.get_ratios(stock, page_ratios))
                    # print({stock: ratios})
                    return {stock: ratios}
                finally:
                    await context.close()
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                # ç¢ºä¿ context è¢«é—œé–‰
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {"stock": stock, "error": str(e)}

    async def get_ratios(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„æ¯”ç‡è³‡æ–™ä¸¦å›å‚³ DataFrameã€‚"""
        URL = f'https://www.roic.ai/quote/{stock}/ratios'
        attempt = 0

        while attempt < retries:
            try:
                await asyncio.sleep(random.uniform(1, 3))
                await page.goto(URL, wait_until='load', timeout=50000)

                # 2025/09/23 æ›´æ–°æ–°é‚è¼¯
                # await page.wait_for_selector('table.w-full.caption-bottom.text-sm.table-fixed', timeout=100000)
                # content = await page.content()
                # dfs = pd.read_html(StringIO(content))
                # return dfs

                # ä¹‹å‰çš„é‚è¼¯
                if await page.query_selector(
                        'div.rounded-lg.bg-card.text-card-foreground.shadow-sm.mx-auto.flex.w-\\[500px\\].flex-col.items-center.border.drop-shadow-lg'):
                    return f'{stock}æ˜¯éç¾åœ‹ä¼æ¥­ï¼Œæ­¤é é¢é ˆä»˜è²»ï¼'
                else:
                    await page.wait_for_selector('table.w-full.caption-bottom.text-sm.table-fixed', timeout=100000)
                    content = await page.content()
                    dfs = pd.read_html(StringIO(content))
                    return dfs

            except Exception as e:
                attempt += 1
                if attempt == retries:
                    return f"Error for {stock}: {e}"

        return f"Failed to retrieve data for {stock}"

    async def run_ratios(self):
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_ratios_data(stock, semaphore) for stock in self.us_stocks]
            result = await asyncio.gather(*tasks)
        finally:
            await self.cleanup()
        return result

    # async def fetch_EPS_PE_MarketCap_data(self, stock, semaphore):
    #     """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„æ•¸æ“šï¼ˆEPS_PE_MarketCapï¼‰ã€‚"""
    #     async with semaphore:
    #         try:
    #             context = await self.browser.new_context(
    #                 user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
    #                 viewport={"width": 800, "height": 600},
    #             )
    #             try:
    #                 page_EPS_PE_MarketCap = await context.new_page()
    #                 EPS_PE_MarketCap = await asyncio.gather(self.get_EPS_PE_MarketCap(stock, page_EPS_PE_MarketCap))
    #                 return {stock: EPS_PE_MarketCap}
    #             finally:
    #                 await context.close()
    #         except Exception as e:
    #             return {"stock": stock, "error": str(e)}

    # async def get_EPS_PE_MarketCap(self, stock, page, retries=3):
    #     """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„EPS/PE/MarketCapæ•¸æ“š - 2025æ–°ç‰ˆHTMLçµæ§‹"""
    #     url = f'https://www.roic.ai/quote/{stock}'
    #     attempt = 0
    #
    #     while attempt < retries:
    #         try:
    #             await asyncio.sleep(random.uniform(1, 3))
    #             await page.goto(url, wait_until='load', timeout=30000)
    #
    #             # ç­‰å¾…é—œéµæŒ‡æ¨™å®¹å™¨è¼‰å…¥
    #             await page.wait_for_selector('div[data-cy="company_header_ratios"]', timeout=30000)
    #
    #             content = await page.content()
    #             soup = BeautifulSoup(content, 'html.parser')
    #
    #             # ğŸ”¥ ä¿®æ­£ï¼šä½¿ç”¨æ–°çš„HTMLçµæ§‹
    #             ratios_container = soup.find('div', {'data-cy': 'company_header_ratios'})
    #
    #             if ratios_container:
    #                 print(f"æ‰¾åˆ° {stock} çš„æŒ‡æ¨™å®¹å™¨")
    #
    #                 # æå–æ‰€æœ‰æŒ‡æ¨™é …ç›®
    #                 metric_items = ratios_container.find_all('div', class_='shrink-0 flex-col')
    #
    #                 if len(metric_items) >= 3:
    #                     dic_data = {}
    #
    #                     for item in metric_items:
    #                         # ğŸ”¥ é—œéµä¿®æ­£ï¼šé©æ‡‰æ–°èˆŠå…©ç¨®classé †åº
    #                         # æ–°ç‰ˆ: class="text-foreground flex text-lg"
    #                         # èˆŠç‰ˆ: class="flex text-lg text-foreground"
    #                         value_span = item.find('span', class_='text-foreground')
    #
    #                         # ç¢ºä¿æ˜¯å¤§å­—ï¼ˆtext-lgï¼‰
    #                         if value_span and 'text-lg' in value_span.get('class', []):
    #                             label_span = item.find('span', class_='text-muted-foreground')
    #
    #                             # ç¢ºä¿æ˜¯å°å­—ï¼ˆtext-sm uppercaseï¼‰
    #                             if label_span and 'text-sm' in label_span.get('class',
    #                                                                           []) and 'uppercase' in label_span.get(
    #                                     'class', []):
    #                                 label = label_span.get_text(strip=True)
    #                                 value_text = value_span.get_text(strip=True)
    #
    #                                 # æ ¹æ“šæ¨™ç±¤é¡å‹é€²è¡Œä¸åŒè™•ç†
    #                                 if label in ['EPS', 'P/E']:
    #                                     try:
    #                                         dic_data[label] = float(value_text)
    #                                     except ValueError:
    #                                         dic_data[label] = value_text
    #                                 else:
    #                                     # Market Cap, Next Earnç­‰ä¿æŒå­—ä¸²
    #                                     dic_data[label] = value_text
    #
    #                     if dic_data:
    #                         print(f"æˆåŠŸæå– {stock} çš„æŒ‡æ¨™æ•¸æ“š: {dic_data}")
    #                         return dic_data
    #                     else:
    #                         print(f"âš ï¸ è§£æå¾Œæ²’æœ‰æœ‰æ•ˆæ•¸æ“š")
    #                 else:
    #                     print(f"âš ï¸ æŒ‡æ¨™é …ç›®æ•¸é‡ä¸è¶³: æ‰¾åˆ° {len(metric_items)} å€‹é …ç›®")
    #
    #             # ğŸ”¥ å‚™ç”¨æ–¹æ¡ˆ 2ï¼šç›´æ¥æœå°‹æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„ span
    #             if not ratios_container or not dic_data:
    #                 print(f"å˜—è©¦å‚™ç”¨æ–¹æ¡ˆæŠ“å– {stock} çš„æŒ‡æ¨™...")
    #
    #                 # æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„æ•¸å€¼ span
    #                 value_spans = soup.find_all('span', class_='text-foreground')
    #                 label_spans = soup.find_all('span', class_='text-muted-foreground')
    #
    #                 # éæ¿¾å‡ºæ­£ç¢ºçš„å…ƒç´ ï¼ˆå¿…é ˆåŒ…å« text-lg å’Œ text-smï¼‰
    #                 filtered_values = [s for s in value_spans if 'text-lg' in s.get('class', [])]
    #                 filtered_labels = [s for s in label_spans if
    #                                    'text-sm' in s.get('class', []) and 'uppercase' in s.get('class', [])]
    #
    #                 if len(filtered_values) >= 3 and len(filtered_labels) >= 3:
    #                     dic_data = {}
    #
    #                     for i in range(min(len(filtered_values), len(filtered_labels))):
    #                         label = filtered_labels[i].get_text(strip=True)
    #                         value_text = filtered_values[i].get_text(strip=True)
    #
    #                         # åªè™•ç†æˆ‘å€‘é—œå¿ƒçš„æŒ‡æ¨™
    #                         if label in ['EPS', 'P/E', 'MARKET CAP', 'Market Cap', 'NEXT EARN', 'Next Earn']:
    #                             if label in ['EPS', 'P/E']:
    #                                 try:
    #                                     dic_data[label] = float(value_text)
    #                                 except ValueError:
    #                                     dic_data[label] = value_text
    #                             else:
    #                                 dic_data[label] = value_text
    #
    #                     if dic_data:
    #                         print(f"å‚™ç”¨æ–¹æ¡ˆæˆåŠŸæå– {stock} çš„æŒ‡æ¨™æ•¸æ“š: {dic_data}")
    #                         return dic_data
    #
    #             # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—
    #             return {'error': f'ç„¡æ³•æ‰¾åˆ° {stock} çš„æŒ‡æ¨™æ•¸æ“š'}
    #
    #         except Exception as e:
    #             attempt += 1
    #             print(f"ç¬¬ {attempt} æ¬¡å˜—è©¦å¤±æ•—: {e}")
    #             if attempt < retries:
    #                 await asyncio.sleep(random.uniform(2, 5))
    #             else:
    #                 return {'error': f'æŠ“å– {stock} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}'}
    #
    #     return {'error': f'Failed to retrieve data for {stock}'}

    async def fetch_combined_summary_and_metrics_data(self, stock, semaphore):
        """åŒæ™‚æŠ“å–Summaryè¡¨æ ¼æ•¸æ“šå’ŒEPS/PE/MarketCapæŒ‡æ¨™æ•¸æ“š"""
        async with semaphore:
            context = None  # ğŸ”¥ åˆå§‹åŒ–
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                    viewport={"width": 800, "height": 600},
                )
                # ğŸ”¥ è¿½è¹¤ context
                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page = await context.new_page()

                    # ä¸€æ¬¡æ€§ç²å–å…©ç¨®æ•¸æ“š
                    summary_data, metrics_data = await self.get_combined_data(stock, page)

                    return {
                        stock: {
                            'summary': summary_data,
                            'metrics': metrics_data
                        }
                    }
                finally:
                    await context.close()
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                # ç¢ºä¿ context è¢«é—œé–‰
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {"stock": stock, "error": str(e)}

    async def get_combined_data(self, stock, page, retries=3):
        """å¾åŒä¸€é é¢åŒæ™‚ç²å–Summaryè¡¨æ ¼å’ŒæŒ‡æ¨™æ•¸æ“š - 2025æ–°ç‰ˆ"""
        URL = f'https://www.roic.ai/quote/{stock}'
        attempt = 0

        while attempt < retries:
            try:
                await asyncio.sleep(random.uniform(1, 3))
                await page.goto(URL, wait_until='load', timeout=50000)

                # ç­‰å¾…å…©ç¨®é—œéµå…ƒç´ è¼‰å…¥å®Œæˆ
                await page.wait_for_selector('table.w-full.caption-bottom.text-sm.table-fixed', timeout=100000)
                await page.wait_for_selector('div[data-cy="company_header_ratios"]', timeout=30000)

                # ç²å–é é¢å…§å®¹
                content = await page.content()

                # ===== 1. è§£æ Summary è¡¨æ ¼æ•¸æ“š =====
                summary_data = None
                try:
                    dfs = pd.read_html(StringIO(content))
                    summary_data = dfs
                    print(f"æˆåŠŸè§£æ {stock} çš„è¡¨æ ¼æ•¸æ“šï¼Œå…± {len(dfs)} å€‹è¡¨æ ¼")
                except Exception as e:
                    print(f"è§£æ {stock} è¡¨æ ¼æ•¸æ“šå¤±æ•—: {e}")
                    summary_data = []

                # ===== 2. è§£ææŒ‡æ¨™æ•¸æ“šï¼ˆEPS/PE/Market Capï¼‰=====
                metrics_data = None
                try:
                    soup = BeautifulSoup(content, 'html.parser')
                    ratios_container = soup.find('div', {'data-cy': 'company_header_ratios'})

                    if ratios_container:
                        metric_items = ratios_container.find_all('div', class_='shrink-0 flex-col')

                        if len(metric_items) >= 3:
                            metrics_data = {}

                            for item in metric_items:
                                # ğŸ”¥ é—œéµä¿®æ­£ï¼šé©æ‡‰æ–°classé †åº
                                value_span = item.find('span', class_='text-foreground')

                                if value_span and 'text-lg' in value_span.get('class', []):
                                    label_span = item.find('span', class_='text-muted-foreground')

                                    if label_span and 'text-sm' in label_span.get('class', []):
                                        label = label_span.get_text(strip=True)
                                        value_text = value_span.get_text(strip=True)

                                        if label in ['EPS', 'P/E']:
                                            try:
                                                metrics_data[label] = float(value_text)
                                            except ValueError:
                                                metrics_data[label] = value_text
                                        else:
                                            metrics_data[label] = value_text

                            print(f"æˆåŠŸè§£æ {stock} çš„æŒ‡æ¨™æ•¸æ“š: {metrics_data}")
                        else:
                            metrics_data = {}
                    else:
                        # ğŸ”¥ å‚™ç”¨æ–¹æ¡ˆ
                        value_spans = [s for s in soup.find_all('span', class_='text-foreground')
                                       if 'text-lg' in s.get('class', [])]
                        label_spans = [s for s in soup.find_all('span', class_='text-muted-foreground')
                                       if 'text-sm' in s.get('class', []) and 'uppercase' in s.get('class', [])]

                        if len(value_spans) >= 3 and len(label_spans) >= 3:
                            metrics_data = {}
                            for i in range(min(len(value_spans), len(label_spans))):
                                label = label_spans[i].get_text(strip=True)
                                value_text = value_spans[i].get_text(strip=True)

                                if label in ['EPS', 'P/E', 'MARKET CAP', 'Market Cap', 'NEXT EARN', 'Next Earn']:
                                    if label in ['EPS', 'P/E']:
                                        try:
                                            metrics_data[label] = float(value_text)
                                        except ValueError:
                                            metrics_data[label] = value_text
                                    else:
                                        metrics_data[label] = value_text

                            if metrics_data:
                                print(f"å‚™ç”¨æ–¹æ¡ˆæˆåŠŸ: {metrics_data}")
                        else:
                            metrics_data = {}

                except Exception as e:
                    print(f"è§£æ {stock} æŒ‡æ¨™æ•¸æ“šå¤±æ•—: {e}")
                    metrics_data = {}

                return summary_data, metrics_data

            except Exception as e:
                attempt += 1
                print(f"ç¬¬ {attempt} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                if attempt == retries:
                    return [], {}
                await asyncio.sleep(random.uniform(2, 5))

        return [], {}

    async def run_combined_summary_and_metrics(self):
        """åŸ·è¡Œåˆä½µçš„Summaryå’ŒæŒ‡æ¨™æ•¸æ“šæŠ“å–"""
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_combined_summary_and_metrics_data(stock, semaphore) for stock in self.stocks]
            result = await asyncio.gather(*tasks)

            # åˆ†é›¢çµæœä»¥ä¿æŒèˆ‡ç¾æœ‰ä»£ç¢¼çš„å…¼å®¹æ€§
            summary_results = []
            metrics_results = []

            for item in result:
                for stock, data in item.items():
                    if stock != "stock" and "error" not in item:  # æ’é™¤éŒ¯èª¤é …ç›®
                        summary_results.append({stock: data['summary']})
                        metrics_results.append({stock: data['metrics']})
                    else:
                        # è™•ç†éŒ¯èª¤æƒ…æ³
                        summary_results.append(item)
                        metrics_results.append(item)

            return summary_results, metrics_results

        finally:
            await self.cleanup()


    # async def EPS_Growth_Rate_and_write_to_excel(self, stock, excel_base64):
    #     """æŠ“å–EPSæˆé•·ç‡ä¸¦å¯«å…¥Excel"""
    #     if '-' in stock:
    #         stock = ''.join(['.' if char == '-' else char for char in stock])
    #
    #     async with aiohttp.ClientSession() as session:
    #         async with session.get(f'https://api.stockboss.io/api/symbol?symbol={stock}') as response:
    #             content = await response.text()
    #             dic = json.loads(content)
    #             # print(dic['symbol']['guru_summary']['summary']['summary']['company_data']['wacc'])
    #             # wacc = float(dic['symbol']['guru_summary']['summary']['summary']['company_data']['wacc'])/100
    #             l_eps_growth5y = []
    #             try:
    #                 EPS_Growth_Rate_3_Year = \
    #                     dic['symbol']['keyratio']['keyratio']['annuals']['3-Year EPS Growth Rate %'][-1]
    #                 EPS_Growth_Rate_5_Year = \
    #                     dic['symbol']['keyratio']['keyratio']['annuals']['5-Year EPS Growth Rate %'][-1]
    #                 EPS_Growth_Rate_10_Year = \
    #                     dic['symbol']['keyratio']['keyratio']['annuals']['10-Year EPS Growth Rate %'][-1]
    #
    #                 EPS_Growth_Rate_3_Year = 0 if EPS_Growth_Rate_3_Year == '-' else EPS_Growth_Rate_3_Year
    #                 EPS_Growth_Rate_5_Year = 0 if EPS_Growth_Rate_5_Year == '-' else EPS_Growth_Rate_5_Year
    #                 EPS_Growth_Rate_10_Year = 0 if EPS_Growth_Rate_10_Year == '-' else EPS_Growth_Rate_10_Year
    #
    #                 l_eps_growth5y = l_eps_growth5y + [EPS_Growth_Rate_3_Year, EPS_Growth_Rate_5_Year,
    #                                                    EPS_Growth_Rate_10_Year]
    #
    #             except KeyError as e:
    #                 return f"EPS_Growth_Rateçš„dictionaryéŒ¯èª¤ï¼š{stock}", excel_base64
    #
    #             # é¸æ“‡æˆé•·ç‡ï¼šå¦‚æœæœ€å°å€¼å¤§æ–¼ 0ï¼Œå‰‡å–æœ€å°å€¼ï¼Œå¦å‰‡å–æœ€å¤§å€¼
    #             selected_growth_rate = min(l_eps_growth5y) / 100 if min(l_eps_growth5y) > 0 else max(
    #                 l_eps_growth5y) / 100
    #             # print(selected_growth_rate)
    #             # print(wacc)
    #             # å¯«å…¥ Excel
    #             try:
    #                 excel_binary = base64.b64decode(excel_base64)
    #                 excel_buffer = io.BytesIO(excel_binary)
    #                 wb = load_workbook(excel_buffer)
    #                 ws = wb.worksheets[3]  # å‡è¨­éœ€è¦å¯«å…¥çš„å·¥ä½œè¡¨æ˜¯ç¬¬å››å€‹
    #
    #                 ws['C3'] = None
    #                 ws['C3'] = selected_growth_rate
    #                 # ws['C6'] = wacc
    #
    #                 output_buffer = io.BytesIO()
    #                 wb.save(output_buffer)
    #                 output_buffer.seek(0)
    #                 modified_base64 = base64.b64encode(output_buffer.read()).decode('utf-8')
    #
    #                 return f"{stock}çš„EPSæˆé•·ç‡åŠWACCæˆåŠŸå¯«å…¥", modified_base64
    #
    #             except Exception as e:
    #                 return f"å¯«å…¥Excelæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", excel_base64

    # async def fetch_seekingalpha_data(self, stock, semaphore):
    #     async with semaphore:
    #         try:
    #             context = await self.browser.new_context(
    #                 user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
    #                 viewport={"width": 800, "height": 600},  # å¢åŠ è¦–çª—å¤§å°
    #                 java_script_enabled=True,  # ç¢ºä¿JavaScriptå•Ÿç”¨
    #             )
    #             try:
    #                 page_summary = await context.new_page()
    #                 summary = await self.get_seekingalpha_html(stock, page_summary)
    #                 return {stock: summary}
    #             finally:
    #                 await context.close()
    #         except Exception as e:
    #             return {"stock": stock, "error": str(e)}

    async def get_seekingalpha_html(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„æ‘˜è¦è³‡æ–™ - PerimeterX CAPTCHA æª¢æ¸¬ç‰ˆ"""
        if '-' in stock:
            stock = ''.join(['.' if char == '-' else char for char in stock])

        URL = f'https://seekingalpha.com/symbol/{stock}/growth'
        attempt = 0

        while attempt < retries:
            try:
                print(f"æ­£åœ¨å˜—è©¦æŠ“å– {stock} çš„è³‡æ–™ (ç¬¬ {attempt + 1} æ¬¡)...")

                # éš¨æ©Ÿç­‰å¾…
                await asyncio.sleep(random.uniform(3, 7))

                # å‰å¾€é é¢
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)

                # ç­‰å¾…é é¢æ¸²æŸ“
                await asyncio.sleep(random.uniform(2, 4))

                # æ¨¡æ“¬äººé¡ç€è¦½è¡Œç‚º
                for _ in range(random.randint(2, 4)):
                    x = random.randint(100, 800)
                    y = random.randint(100, 600)
                    await page.mouse.move(x, y)
                    await asyncio.sleep(random.uniform(0.3, 0.8))

                # æ»¾å‹•é é¢
                scroll_positions = [200, 400, 600, 400, 200]
                for pos in scroll_positions:
                    await page.evaluate(f'window.scrollTo(0, {pos})')
                    await asyncio.sleep(random.uniform(0.5, 1.2))

                # ğŸ”¥ æ–¹æ³• 1: æª¢æ¸¬ PerimeterX CAPTCHAï¼ˆç²¾æº–æª¢æ¸¬ï¼‰
                px_captcha = await page.query_selector('#px-captcha-wrapper, #px-captcha, .px-captcha-container')

                if px_captcha:
                    # ç¢ºèªæ˜¯å¦å¯è¦‹
                    is_visible = await px_captcha.is_visible()
                    if is_visible:
                        print(f"\n{'ğŸ”´' * 30}")
                        print(f"âš ï¸  {stock} åµæ¸¬åˆ° PerimeterX é©—è­‰ï¼")
                        print("âš ï¸  è«‹åœ¨ç€è¦½å™¨ä¸­å®Œæˆã€ŒæŒ‰å£“ä¸æ”¾ã€é©—è­‰")
                        print("âš ï¸  é©—è­‰å®Œæˆå¾Œç¨‹å¼å°‡è‡ªå‹•ç¹¼çºŒ...")
                        print(f"{'ğŸ”´' * 30}\n")

                        # ç„¡é™ç­‰å¾…ç›´åˆ° CAPTCHA æ¶ˆå¤±
                        await self._wait_for_px_captcha_resolution(stock, page)

                # ğŸ”¥ æ–¹æ³• 2: åå‘æª¢æ¸¬ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
                target_section = await page.query_selector('section[data-test-id="card-container-growth-rates"]')

                if not target_section:
                    print(f"\n{'ğŸŸ¡' * 30}")
                    print(f"âš ï¸  {stock} ç›®æ¨™æ•¸æ“šæœªå‡ºç¾")
                    print("âš ï¸  å¯èƒ½éœ€è¦é©—è­‰æˆ–é é¢è¼‰å…¥å»¶é²")
                    print("âš ï¸  ç­‰å¾…ä¸­...")
                    print(f"{'ğŸŸ¡' * 30}\n")

                    # ç„¡é™ç­‰å¾…ç›´åˆ°ç›®æ¨™å‡ºç¾
                    await self._wait_for_target_element(stock, page)

                # ğŸ”¥ ç¢ºèªç›®æ¨™å…ƒç´ å·²è¼‰å…¥
                await page.wait_for_selector(
                    'section[data-test-id="card-container-growth-rates"] table[data-test-id="table"]',
                    timeout=10000
                )
                await page.wait_for_selector(
                    'section[data-test-id="card-container-growth-rates"] th:has-text("Revenue")',
                    timeout=10000
                )

                await asyncio.sleep(2)

                # ===== é–‹å§‹è§£ææ•¸æ“š =====
                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')

                growth_section = soup.find('section', {'data-test-id': 'card-container-growth-rates'})

                if not growth_section:
                    raise Exception("æœªæ‰¾åˆ° Growth Rates section")

                target_table = growth_section.find('table', {'data-test-id': 'table'})

                if target_table:
                    print("æ‰¾åˆ°æ­£ç¢ºçš„ Growth Rates è¡¨æ ¼ï¼Œé–‹å§‹è§£æ...")

                    # è§£æè¡¨é ­
                    header_row = target_table.find('thead').find('tr') if target_table.find('thead') else None
                    headers = []
                    if header_row:
                        header_cells = header_row.find_all('th')
                        for cell in header_cells:
                            div_text = cell.find('div')
                            if div_text:
                                header_text = div_text.get_text(strip=True)
                            else:
                                header_text = cell.get_text(strip=True)
                            headers.append(header_text)

                    print(f"è¡¨é ­: {headers}")

                    # é©—è­‰è¡¨é ­çµæ§‹
                    expected_headers = ['YoY', '3Y', '5Y', '10Y']
                    if not all(h in headers for h in expected_headers):
                        raise Exception("è¡¨é ­çµæ§‹ä¸æ­£ç¢º")

                    # æ‰¾åˆ° 5Y å’Œ 10Y çš„ä½ç½®
                    try:
                        header_5y_index = headers.index('5Y')
                        header_10y_index = headers.index('10Y')
                        print(f"5Yä½ç½®: {header_5y_index}, 10Yä½ç½®: {header_10y_index}")
                    except ValueError as e:
                        raise Exception(f"æ‰¾ä¸åˆ°5Yæˆ–10Yè¡¨é ­: {e}")

                    # è§£æè¡¨æ ¼å…§å®¹
                    tbody = target_table.find('tbody')
                    if tbody:
                        rows = tbody.find_all('tr')

                        for row in rows:
                            row_data = []

                            # è™•ç†ç¬¬ä¸€å€‹thï¼ˆè¡Œæ¨™é¡Œï¼‰
                            th = row.find('th')
                            if th:
                                div_text = th.find('div')
                                if div_text:
                                    row_name = div_text.get_text(strip=True)
                                else:
                                    row_name = th.get_text(strip=True)
                                row_data.append(row_name)

                            # è™•ç†å…¶ä»–td
                            tds = row.find_all('td')
                            for td in tds:
                                div_text = td.find('div')
                                if div_text:
                                    cell_value = div_text.get_text(strip=True)
                                else:
                                    cell_value = td.get_text(strip=True)
                                row_data.append(cell_value)

                            # æª¢æŸ¥æ˜¯å¦ç‚ºRevenueè¡Œ
                            if 'Revenue' in row_data[0] and 'Revenue per Share' not in row_data[0]:
                                print(f"æ‰¾åˆ°Revenueè¡Œ: {row_data}")

                                if len(row_data) > max(header_5y_index, header_10y_index):
                                    result = {
                                        "5Y": row_data[header_5y_index],
                                        "10Y": row_data[header_10y_index]
                                    }
                                    print(f"æå–çµæœ: {result}")
                                    return result
                                else:
                                    return {"error": f"Revenueè¡Œæ•¸æ“šä¸è¶³: {row_data}"}

                        return {"error": "æœªæ‰¾åˆ°Revenueè¡Œ"}
                    else:
                        return {"error": "æœªæ‰¾åˆ°tbody"}
                else:
                    return {"error": "æœªæ‰¾åˆ°Growth Ratesè¡¨æ ¼"}

            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                attempt += 1
                if attempt < retries:
                    wait_time = random.uniform(20, 40)
                    print(f"ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(wait_time)

        return {"error": f"Failed to retrieve data for {stock} after {retries} attempts"}

    async def _wait_for_px_captcha_resolution(self, stock, page):
        """ç­‰å¾… PerimeterX CAPTCHA è¢«è§£æ±ºï¼ˆç„¡é™ç­‰å¾…ï¼‰"""

        check_count = 0

        while True:
            await asyncio.sleep(5)  # æ¯ 5 ç§’æª¢æŸ¥ä¸€æ¬¡
            check_count += 1

            # æª¢æŸ¥ CAPTCHA æ˜¯å¦é‚„åœ¨
            px_captcha = await page.query_selector('#px-captcha-wrapper, #px-captcha')

            if px_captcha:
                is_visible = await px_captcha.is_visible()
                if not is_visible:
                    # CAPTCHA å…ƒç´ é‚„åœ¨ä½†ä¸å¯è¦‹äº†
                    print(f"âœ… {stock} PerimeterX é©—è­‰å·²é€šéï¼")
                    break
            else:
                # CAPTCHA å…ƒç´ å®Œå…¨æ¶ˆå¤±
                print(f"âœ… {stock} PerimeterX é©—è­‰å·²é€šéï¼")
                break

            # æ¯ 20 ç§’æç¤ºä¸€æ¬¡
            if check_count % 4 == 0:
                elapsed = check_count * 5
                print(f"   {stock} ç­‰å¾… PerimeterX é©—è­‰... (å·²ç­‰å¾… {elapsed} ç§’)")

        # é©—è­‰é€šéå¾Œå†ç­‰å¾…ä¸€ä¸‹
        await asyncio.sleep(random.uniform(2, 4))

    async def _wait_for_target_element(self, stock, page):
        """ç­‰å¾…ç›®æ¨™å…ƒç´ å‡ºç¾ï¼ˆç„¡é™ç­‰å¾…ï¼‰"""

        check_count = 0

        while True:
            await asyncio.sleep(5)  # æ¯ 5 ç§’æª¢æŸ¥ä¸€æ¬¡
            check_count += 1

            # æª¢æŸ¥ç›®æ¨™å…ƒç´ æ˜¯å¦å‡ºç¾
            target = await page.query_selector('section[data-test-id="card-container-growth-rates"]')

            if target:
                print(f"âœ… {stock} ç›®æ¨™æ•¸æ“šå·²å‡ºç¾ï¼")
                break

            # æ¯ 20 ç§’æç¤ºä¸€æ¬¡
            if check_count % 4 == 0:
                elapsed = check_count * 5
                print(f"   {stock} ç­‰å¾…ç›®æ¨™æ•¸æ“š... (å·²ç­‰å¾… {elapsed} ç§’)")

        # æ•¸æ“šå‡ºç¾å¾Œå†ç­‰å¾…ä¸€ä¸‹
        await asyncio.sleep(2)

    async def run_seekingalpha(self):
        """åŸ·è¡Œ SeekingAlpha æ•¸æ“šæŠ“å– - å¼·åˆ¶æœ‰é ­æ¨¡å¼è™•ç† Cloudflare"""

        # ğŸ”¥ è‡¨æ™‚ä¿å­˜åŸå§‹ headless è¨­å®š
        original_headless = self.headless

        # ğŸ”¥ å¼·åˆ¶ä½¿ç”¨æœ‰é ­æ¨¡å¼ï¼ˆé¡¯ç¤ºç€è¦½å™¨ï¼‰
        self.headless = False

        try:
            await self.setup_browser()

            context = await self.browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                viewport={"width": 1920, "height": 1080},
                java_script_enabled=True,
            )

            try:
                page = await context.new_page()
                result = []

                # ä¾åºè™•ç†æ¯å€‹è‚¡ç¥¨
                for i, stock in enumerate(self.stocks):
                    print(f"\n{'=' * 50}")
                    print(f"æ­£åœ¨è™•ç† {stock} ({i + 1}/{len(self.stocks)})...")
                    print(f"{'=' * 50}")

                    stock_data = await self.get_seekingalpha_html(stock, page)
                    result.append({stock: stock_data})

                    # ğŸ”¥ å¼·åŒ–: å¢åŠ å»¶é²è®ŠåŒ–å¹…åº¦
                    if i < len(self.stocks) - 1:
                        base_delay = 3 + (i * 2)
                        wait_time = random.uniform(base_delay, base_delay + 10)
                        print(f"\nâ³ ç­‰å¾… {wait_time:.1f} ç§’å¾Œè™•ç†ä¸‹ä¸€å€‹è‚¡ç¥¨...")
                        await asyncio.sleep(wait_time)

                return result

            finally:
                await context.close()

        finally:
            # ğŸ”¥ æ¢å¾©åŸå§‹è¨­å®š
            self.headless = original_headless
            await self.cleanup()

    async def fetch_wacc_data(self, stock, semaphore):
        async with semaphore:
            context = None
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    java_script_enabled=True,
                    locale='en-US',
                    timezone_id='America/New_York',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.9',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                        'Sec-Fetch-Dest': 'document',
                        'Sec-Fetch-Mode': 'navigate',
                        'Sec-Fetch-Site': 'none',
                        'Cache-Control': 'max-age=0',
                    }
                )

                # æ³¨å…¥ååµæ¸¬è…³æœ¬
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });

                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };

                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                            Promise.resolve({ state: Notification.permission }) :
                            originalQuery(parameters)
                    );

                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });

                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['en-US', 'en']
                    });
                """)

                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page = await context.new_page()
                    wacc_value = await self.get_wacc_html(stock, page)
                    return {stock: wacc_value}
                finally:
                    await context.close()
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                print(f"âŒ {stock} ç™¼ç”ŸéŒ¯èª¤: {e}")
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {stock: None}

    async def get_wacc_html(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„WACCè³‡æ–™ä¸¦å›å‚³intæ•¸å€¼ã€‚"""
        if '-' in stock:
            stock = ''.join(['.' if char == '-' else char for char in stock])

        URL = f'https://www.gurufocus.com/term/wacc/{stock}'
        attempt = 0

        while attempt < retries:
            try:
                print(f"æ­£åœ¨å˜—è©¦æŠ“å– {stock} çš„WACCè³‡æ–™ (ç¬¬ {attempt + 1} æ¬¡)...")

                # éš¨æ©Ÿç­‰å¾…æ™‚é–“
                await asyncio.sleep(random.uniform(3, 6))

                # å‰å¾€é é¢
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)

                # æ¨¡æ“¬äººé¡ç€è¦½è¡Œç‚º
                await asyncio.sleep(random.uniform(1, 2))
                await page.evaluate('window.scrollTo(0, 200)')
                await asyncio.sleep(random.uniform(0.5, 1))

                # ç­‰å¾…é—œéµå…§å®¹è¼‰å…¥
                try:
                    await page.wait_for_selector('h1', timeout=30000)
                    await asyncio.sleep(2)
                except Exception as e:
                    print(f"ç­‰å¾…é é¢è¼‰å…¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                # ç²å–é é¢å…§å®¹
                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')

                # å°‹æ‰¾åŒ…å«WACCæ•¸å€¼çš„ç‰¹å®šå…ƒç´ 
                wacc_value = None

                # æ–¹æ³•1: å°‹æ‰¾åŒ…å«":X.X% (As of"æ¨¡å¼çš„fontæ¨™ç±¤
                font_elements = soup.find_all('font', style=True)
                for font in font_elements:
                    text = font.get_text(strip=True)
                    if '% (As of' in text and text.startswith(':'):
                        # æå–ç™¾åˆ†æ¯”æ•¸å€¼
                        match = re.search(r':(\d+\.?\d*)%', text)
                        if match:
                            wacc_value = float(match.group(1)) / 100
                            print(f"âœ“ æ‰¾åˆ° {stock} çš„WACCå€¼: {wacc_value}")
                            break

                if wacc_value is not None:
                    return wacc_value
                else:
                    print(f"âš ï¸ æœªèƒ½æ‰¾åˆ° {stock} çš„WACCæ•¸å€¼")
                    return None

            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                attempt += 1
                if attempt < retries:
                    wait_time = random.uniform(8, 15)
                    print(f"ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(wait_time)

        print(f"âŒ Failed to retrieve WACC data for {stock} after {retries} attempts")
        return None

    async def run_wacc(self):
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_wacc_data(stock, semaphore) for stock in self.stocks]
            result = await asyncio.gather(*tasks)
        finally:
            await self.cleanup()
        return result


    async def fetch_TradingView_data(self, stock, semaphore):
        async with semaphore:
            context = None
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    java_script_enabled=True,
                    locale='zh-TW',
                    timezone_id='Asia/Taipei',
                    # æ·»åŠ æ›´å¤šçœŸå¯¦ç€è¦½å™¨ç‰¹å¾µ
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                        'Sec-Fetch-Dest': 'document',
                        'Sec-Fetch-Mode': 'navigate',
                        'Sec-Fetch-Site': 'none',
                        'Cache-Control': 'max-age=0',
                    }
                )

                # æ³¨å…¥ååµæ¸¬è…³æœ¬
                await context.add_init_script("""
                    // è¦†è“‹ webdriver æª¢æ¸¬
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });

                    // è¦†è“‹ Chrome ç‰¹å¾µ
                    window.chrome = {
                        runtime: {}
                    };

                    // è¦†è“‹ permissions
                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                            Promise.resolve({ state: Notification.permission }) :
                            originalQuery(parameters)
                    );

                    // è¦†è“‹ plugins
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });

                    // è¦†è“‹ languages
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-TW', 'zh', 'en-US', 'en']
                    });
                """)

                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page = await context.new_page()
                    beta_value = await self.get_TradingView_html(stock, page)
                    return {stock: beta_value}
                finally:
                    await context.close()
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                # ç¢ºä¿ context è¢«é—œé–‰
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {stock: None}  # å¦‚æœå‡ºéŒ¯è¿”å›None

    async def get_TradingView_html(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„trading-viewè³‡æ–™ - ä½¿ç”¨ Schwab API çš„ exchangeName"""

        # ğŸ”¥ ç§»é™¤ yfinanceï¼Œæ”¹ç”¨ stock_exchanges
        exchange_name = self.stock_exchanges.get(stock, 'NYSE')  # é è¨­ NYSE

        if '-' in stock:
            stock = ''.join(['.' if char == '-' else char for char in stock])

        # ğŸ”¥ ç›´æ¥ä½¿ç”¨ exchangeNameï¼Œä¸éœ€è¦å†åšå°æ‡‰
        URL = f'https://www.tradingview.com/symbols/{exchange_name}-{stock}/financials-earnings/?earnings-period=FY&revenues-period=FY'

        attempt = 0

        while attempt < retries:
            try:
                print(f"æ­£åœ¨å˜—è©¦æŠ“å– {stock} çš„trading-viewè³‡æ–™ (ç¬¬ {attempt + 1} æ¬¡)...")

                # ğŸ”¥ å¼·åŒ–: æ›´é•·çš„éš¨æ©Ÿç­‰å¾…
                await asyncio.sleep(random.uniform(3, 7))

                # å‰å¾€é é¢
                await page.goto(URL, wait_until='networkidle', timeout=60000)

                # ğŸ”¥ å¼·åŒ–: æ›´çœŸå¯¦çš„ç€è¦½è¡Œç‚º
                await asyncio.sleep(random.uniform(2, 4))

                # æ¨¡æ“¬æ»‘é¼ ç§»å‹•è»Œè·¡
                for _ in range(random.randint(2, 4)):
                    x = random.randint(100, 800)
                    y = random.randint(100, 600)
                    await page.mouse.move(x, y)
                    await asyncio.sleep(random.uniform(0.3, 0.8))

                # æ»¾å‹•é é¢
                scroll_positions = [200, 400, 600, 400, 200]
                for pos in scroll_positions:
                    await page.evaluate(f'window.scrollTo(0, {pos})')
                    await asyncio.sleep(random.uniform(0.5, 1.2))

                # ç­‰å¾…é—œéµå…§å®¹è¼‰å…¥
                try:
                    await page.wait_for_selector('h1', timeout=30000)
                    await asyncio.sleep(3)
                except Exception as e:
                    print(f"ç­‰å¾…é é¢è¼‰å…¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                # ç²å–é é¢å…§å®¹
                content = await page.content()

                # ä½¿ç”¨BeautifulSoupè§£ætrading-viewæ•¸å€¼
                soup = BeautifulSoup(content, 'html.parser')

                # è§£æå¹´ä»½
                years = []
                year_elements = soup.find_all('div', class_='value-OxVAcLqi')
                for element in year_elements:
                    text = element.get_text(strip=True)
                    if text.isdigit() and len(text) == 4:
                        years.append(int(text))

                # å¦‚æœæ²’æ‰¾åˆ°å¹´ä»½ï¼Œå˜—è©¦å¦ä¸€ç¨®æ–¹å¼
                if not years:
                    values_container = soup.find('div', class_='values-AtxjAQkN')
                    if values_container:
                        year_divs = values_container.find_all('div', class_='value-OxVAcLqi')
                        for div in year_divs:
                            text = div.get_text(strip=True)
                            if text.isdigit() and len(text) == 4:
                                years.append(int(text))

                if not years:
                    print(f"ç„¡æ³•æ‰¾åˆ°å¹´ä»½è³‡æ–™å°æ–¼ {stock}")
                    return None

                # åˆå§‹åŒ–è³‡æ–™å­—å…¸
                data = {
                    'Year': years,
                    'Reported': [None] * len(years),
                    'Estimate': [None] * len(years),
                    'Surprise': [None] * len(years)
                }

                # è§£æä¸‰ç¨®é¡å‹çš„è³‡æ–™
                data_types = ['Reported', 'Estimate', 'Surprise']

                for data_type in data_types:
                    container = soup.find('div', {'data-name': data_type})
                    if not container:
                        print(f"æ‰¾ä¸åˆ° {data_type} è³‡æ–™å®¹å™¨")
                        continue

                    values_section = container.find('div', class_='values-C9MdAMrq')
                    if not values_section:
                        print(f"æ‰¾ä¸åˆ° {data_type} çš„æ•¸å€¼å€åŸŸ")
                        continue

                    value_containers = values_section.find_all('div', class_='container-OxVAcLqi')

                    for i, value_container in enumerate(value_containers):
                        if i >= len(years):
                            break

                        lock_button = value_container.find('button', class_='lockButton-N_j3rnsK')
                        if lock_button:
                            continue

                        value_div = value_container.find('div', class_='value-OxVAcLqi')
                        if value_div:
                            value = value_div.get_text(strip=True)
                            if value == 'â€”' or value == '-':
                                value = None
                            elif value.startswith('â€ª') and value.endswith('â€¬'):
                                value = value.strip('â€ªâ€¬')

                            data[data_type][i] = value

                # å»ºç«‹DataFrame
                df_original = pd.DataFrame(data)

                # åªä¿ç•™æœ‰è³‡æ–™çš„è¡Œ
                mask = df_original[['Reported', 'Estimate', 'Surprise']].notna().any(axis=1)
                df_filtered = df_original[mask].reset_index(drop=True)

                # è½‰æ›æˆæ©«å‘æ ¼å¼
                if len(df_filtered) > 0:
                    years_list = df_filtered['Year'].tolist()

                    transposed_data = {
                        'Year': years_list,
                        'Reported': df_filtered['Reported'].tolist(),
                        'Estimate': df_filtered['Estimate'].tolist(),
                        'Surprise': df_filtered['Surprise'].tolist()
                    }

                    result_dict = {}

                    for i, year in enumerate(years_list):
                        result_dict[str(year)] = [
                            transposed_data['Reported'][i],
                            transposed_data['Estimate'][i],
                            transposed_data['Surprise'][i]
                        ]

                    df_final = pd.DataFrame(result_dict, index=['Reported', 'Estimate', 'Surprise'])

                    print(f"æˆåŠŸè§£æ {stock} çš„è³‡æ–™ï¼Œæ ¼å¼ç‚º {df_final.shape[1]} å¹´ä»½ x {df_final.shape[0]} æŒ‡æ¨™")
                    return df_final
                else:
                    print(f"æœªæ‰¾åˆ° {stock} çš„æœ‰æ•ˆè³‡æ–™")
                    return None

            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                attempt += 1
                if attempt < retries:
                    wait_time = random.uniform(20, 40)  # ğŸ”¥ å¢åŠ é‡è©¦ç­‰å¾…æ™‚é–“
                    print(f"ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(wait_time)

        print(f"Failed to retrieve TradingView data for {stock} after {retries} attempts")
        return None

    async def run_TradingView(self):
        """æ‰¹æ¬¡åŸ·è¡Œ TradingView æ•¸æ“šæŠ“å– - å…ˆé›†ä¸­è™•ç† CAPTCHAï¼Œå†æ‰¹æ¬¡çˆ¬èŸ²"""

        # ğŸ”¥ è‡¨æ™‚ä¿å­˜åŸå§‹ headless è¨­å®š
        original_headless = self.headless

        # ğŸ”¥ å¼·åˆ¶ä½¿ç”¨æœ‰é ­æ¨¡å¼ï¼ˆé¡¯ç¤ºç€è¦½å™¨ï¼‰
        self.headless = False

        try:
            await self.setup_browser()

            print("\n" + "=" * 60)
            print("ğŸš€ éšæ®µ 1: é›†ä¸­è™•ç† TradingView CAPTCHA é©—è­‰")
            print("âš ï¸  å³å°‡æ‰“é–‹æ‰€æœ‰è‚¡ç¥¨çš„é é¢")
            print("âš ï¸  è«‹ä¾åºå®Œæˆæ‰€æœ‰ CAPTCHA é©—è­‰")
            print("âš ï¸  å®Œæˆæ‰€æœ‰é©—è­‰å¾Œï¼Œç¨‹å¼å°‡è‡ªå‹•é–‹å§‹æŠ“å–æ•¸æ“š")
            print("=" * 60 + "\n")

            # ğŸ”¥ éšæ®µ 1: æ‰“é–‹æ‰€æœ‰é é¢ä¸¦è™•ç† CAPTCHA
            pages_and_contexts = await self._open_all_tradingview_pages()

            if not pages_and_contexts:
                print("âŒ ç„¡æ³•æ‰“é–‹ä»»ä½•é é¢")
                return []

            print("\n" + "=" * 60)
            print("âœ… æ‰€æœ‰ CAPTCHA å·²é€šéï¼")
            print("ğŸš€ éšæ®µ 2: é–‹å§‹æ‰¹æ¬¡æŠ“å– TradingView æ•¸æ“š")
            print("=" * 60 + "\n")

            # ğŸ”¥ éšæ®µ 2: æ‰¹æ¬¡æŠ“å–æ•¸æ“š
            result = []
            for i, (stock, page, context) in enumerate(pages_and_contexts):
                print(f"\n{'=' * 50}")
                print(f"æŠ“å– {stock} çš„ TradingView æ•¸æ“š ({i + 1}/{len(pages_and_contexts)})")
                print(f"{'=' * 50}")

                try:
                    tradingview_data = await self._extract_tradingview_from_page(stock, page)
                    result.append({stock: tradingview_data})

                    if tradingview_data is not None:
                        print(f"âœ“ {stock}: æˆåŠŸæŠ“å– {tradingview_data.shape[1]} å¹´ä»½æ•¸æ“š")
                    else:
                        print(f"âš ï¸ {stock}: ç„¡æ•¸æ“š")
                except Exception as e:
                    print(f"âŒ {stock} æŠ“å–å¤±æ•—: {e}")
                    result.append({stock: None})

                # å»¶é²ï¼ˆæœ€å¾Œä¸€å€‹ä¸å»¶é²ï¼‰
                if i < len(pages_and_contexts) - 1:
                    await asyncio.sleep(random.uniform(0.5, 1.5))

            # ğŸ”¥ é—œé–‰æ‰€æœ‰é é¢å’Œ context
            print("\nğŸ§¹ æ¸…ç†è³‡æº...")
            for stock, page, context in pages_and_contexts:
                try:
                    await context.close()
                except:
                    pass

            return result

        finally:
            # ğŸ”¥ æ¢å¾©åŸå§‹è¨­å®š
            self.headless = original_headless
            await self.cleanup()

    async def _open_all_tradingview_pages(self):
        """æ‰“é–‹æ‰€æœ‰è‚¡ç¥¨çš„ TradingView é é¢ - ä½¿ç”¨ Schwab API çš„ exchangeName"""
        pages_and_contexts = []

        for i, stock in enumerate(self.stocks):
            print(f"\n{'=' * 50}")
            print(f"æ‰“é–‹ {stock} çš„ TradingView é é¢ ({i + 1}/{len(self.stocks)})")
            print(f"{'=' * 50}")

            try:
                # å‰µå»ºæ–°çš„ context
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    java_script_enabled=True,
                    locale='zh-TW',
                    timezone_id='Asia/Taipei',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )

                # æ³¨å…¥ååµæ¸¬è…³æœ¬
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-TW', 'zh', 'en-US', 'en']
                    });
                """)

                page = await context.new_page()

                # ğŸ”¥ ç§»é™¤ yfinanceï¼Œæ”¹ç”¨ stock_exchanges
                exchange_name = self.stock_exchanges.get(stock, 'NYSE')  # é è¨­ NYSE

                stock_symbol = ''.join(['.' if char == '-' else char for char in stock]) if '-' in stock else stock

                # ğŸ”¥ ç›´æ¥ä½¿ç”¨ exchangeName
                URL = f'https://www.tradingview.com/symbols/{exchange_name}-{stock_symbol}/financials-earnings/?earnings-period=FY&revenues-period=FY'

                # è¨ªå•é é¢
                await asyncio.sleep(random.uniform(2, 4))
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)
                await asyncio.sleep(random.uniform(2, 3))

                # ğŸ”¥ æª¢æŸ¥ CAPTCHAï¼ˆç„¡é™ç­‰å¾…ï¼‰
                await self._wait_for_captcha_resolution(stock, page)

                # ä¿å­˜é é¢å’Œ context
                pages_and_contexts.append((stock, page, context))
                print(f"âœ“ {stock} é é¢å·²å°±ç·’")

                # æ¯å€‹é é¢ä¹‹é–“å»¶é²
                if i < len(self.stocks) - 1:
                    await asyncio.sleep(random.uniform(1, 2))

            except Exception as e:
                print(f"âŒ {stock} é é¢æ‰“é–‹å¤±æ•—: {e}")
                if context:
                    try:
                        await context.close()
                    except:
                        pass

        return pages_and_contexts

    async def _extract_tradingview_from_page(self, stock, page):
        """å¾å·²è¼‰å…¥çš„é é¢ä¸­æå– TradingView æ•¸æ“š"""
        try:
            # æ¨¡æ“¬äººé¡ç€è¦½è¡Œç‚ºï¼ˆèˆ‡ get_TradingView_html ç›¸åŒçš„é‚è¼¯ï¼‰
            scroll_positions = [200, 400, 600, 400, 200]
            for pos in scroll_positions:
                await page.evaluate(f'window.scrollTo(0, {pos})')
                await asyncio.sleep(random.uniform(0.3, 0.6))

            # ç­‰å¾…é—œéµå…§å®¹è¼‰å…¥
            try:
                await page.wait_for_selector('h1', timeout=30000)
                await asyncio.sleep(3)
            except Exception as e:
                print(f"ç­‰å¾…é é¢è¼‰å…¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

            # ç²å–é é¢å…§å®¹
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')

            # === ä»¥ä¸‹æ˜¯åŸæœ‰çš„è§£æé‚è¼¯ ===

            # è§£æå¹´ä»½
            years = []
            year_elements = soup.find_all('div', class_='value-OxVAcLqi')
            for element in year_elements:
                text = element.get_text(strip=True)
                if text.isdigit() and len(text) == 4:
                    years.append(int(text))

            if not years:
                values_container = soup.find('div', class_='values-AtxjAQkN')
                if values_container:
                    year_divs = values_container.find_all('div', class_='value-OxVAcLqi')
                    for div in year_divs:
                        text = div.get_text(strip=True)
                        if text.isdigit() and len(text) == 4:
                            years.append(int(text))

            if not years:
                print(f"ç„¡æ³•æ‰¾åˆ°å¹´ä»½è³‡æ–™å°æ–¼ {stock}")
                return None

            # åˆå§‹åŒ–è³‡æ–™å­—å…¸
            data = {
                'Year': years,
                'Reported': [None] * len(years),
                'Estimate': [None] * len(years),
                'Surprise': [None] * len(years)
            }

            # è§£æä¸‰ç¨®é¡å‹çš„è³‡æ–™
            data_types = ['Reported', 'Estimate', 'Surprise']

            for data_type in data_types:
                container = soup.find('div', {'data-name': data_type})
                if not container:
                    continue

                values_section = container.find('div', class_='values-C9MdAMrq')
                if not values_section:
                    continue

                value_containers = values_section.find_all('div', class_='container-OxVAcLqi')

                for i, value_container in enumerate(value_containers):
                    if i >= len(years):
                        break

                    lock_button = value_container.find('button', class_='lockButton-N_j3rnsK')
                    if lock_button:
                        continue

                    value_div = value_container.find('div', class_='value-OxVAcLqi')
                    if value_div:
                        value = value_div.get_text(strip=True)
                        if value == 'â€”' or value == '-':
                            value = None
                        elif value.startswith('â€ª') and value.endswith('â€¬'):
                            value = value.strip('â€ªâ€¬')
                        data[data_type][i] = value

            # å»ºç«‹DataFrame
            df_original = pd.DataFrame(data)
            mask = df_original[['Reported', 'Estimate', 'Surprise']].notna().any(axis=1)
            df_filtered = df_original[mask].reset_index(drop=True)

            # è½‰æ›æˆæ©«å‘æ ¼å¼
            if len(df_filtered) > 0:
                years_list = df_filtered['Year'].tolist()
                transposed_data = {
                    'Year': years_list,
                    'Reported': df_filtered['Reported'].tolist(),
                    'Estimate': df_filtered['Estimate'].tolist(),
                    'Surprise': df_filtered['Surprise'].tolist()
                }

                result_dict = {}
                for i, year in enumerate(years_list):
                    result_dict[str(year)] = [
                        transposed_data['Reported'][i],
                        transposed_data['Estimate'][i],
                        transposed_data['Surprise'][i]
                    ]

                df_final = pd.DataFrame(result_dict, index=['Reported', 'Estimate', 'Surprise'])
                print(f"æˆåŠŸè§£æ {stock} çš„è³‡æ–™")
                return df_final
            else:
                return None

        except Exception as e:
            print(f"æå– TradingView æ•¸æ“šå¤±æ•—: {e}")
            return None

    async def run_beta(self):
        """æ‰¹æ¬¡åŸ·è¡Œ Beta å€¼æŠ“å– - å…ˆé›†ä¸­è™•ç† CAPTCHAï¼Œå†æ‰¹æ¬¡çˆ¬èŸ²"""

        # ğŸ”¥ è‡¨æ™‚ä¿å­˜åŸå§‹ headless è¨­å®š
        original_headless = self.headless

        # ğŸ”¥ å¼·åˆ¶ä½¿ç”¨æœ‰é ­æ¨¡å¼ï¼ˆé¡¯ç¤ºç€è¦½å™¨ï¼‰
        self.headless = False

        try:
            await self.setup_browser()

            print("\n" + "=" * 60)
            print("ğŸš€ éšæ®µ 1: é›†ä¸­è™•ç† CAPTCHA é©—è­‰")
            print("âš ï¸  å³å°‡æ‰“é–‹æ‰€æœ‰è‚¡ç¥¨çš„é é¢")
            print("âš ï¸  è«‹ä¾åºå®Œæˆæ‰€æœ‰ CAPTCHA é©—è­‰")
            print("âš ï¸  å®Œæˆæ‰€æœ‰é©—è­‰å¾Œï¼Œç¨‹å¼å°‡è‡ªå‹•é–‹å§‹æŠ“å–æ•¸æ“š")
            print("=" * 60 + "\n")

            # ğŸ”¥ éšæ®µ 1: æ‰“é–‹æ‰€æœ‰é é¢ä¸¦è™•ç† CAPTCHA
            pages_and_contexts = await self._open_all_beta_pages()

            if not pages_and_contexts:
                print("âŒ ç„¡æ³•æ‰“é–‹ä»»ä½•é é¢")
                return []

            print("\n" + "=" * 60)
            print("âœ… æ‰€æœ‰ CAPTCHA å·²é€šéï¼")
            print("ğŸš€ éšæ®µ 2: é–‹å§‹æ‰¹æ¬¡æŠ“å– Beta å€¼")
            print("=" * 60 + "\n")

            # ğŸ”¥ éšæ®µ 2: æ‰¹æ¬¡æŠ“å–æ•¸æ“š
            result = []
            for i, (stock, page, context) in enumerate(pages_and_contexts):
                print(f"\n{'=' * 50}")
                print(f"æŠ“å– {stock} çš„ Beta å€¼ ({i + 1}/{len(pages_and_contexts)})")
                print(f"{'=' * 50}")

                try:
                    beta_value = await self._extract_beta_from_page(stock, page)
                    result.append({stock: beta_value})
                    print(f"âœ“ {stock}: {beta_value}")
                except Exception as e:
                    print(f"âŒ {stock} æŠ“å–å¤±æ•—: {e}")
                    result.append({stock: None})

                # å»¶é²ï¼ˆæœ€å¾Œä¸€å€‹ä¸å»¶é²ï¼‰
                if i < len(pages_and_contexts) - 1:
                    await asyncio.sleep(random.uniform(0.5, 1.5))

            # ğŸ”¥ é—œé–‰æ‰€æœ‰é é¢å’Œ context
            print("\nğŸ§¹ æ¸…ç†è³‡æº...")
            for stock, page, context in pages_and_contexts:
                try:
                    await context.close()
                except:
                    pass

            return result

        finally:
            # ğŸ”¥ æ¢å¾©åŸå§‹è¨­å®š
            self.headless = original_headless
            await self.cleanup()

    async def _open_all_beta_pages(self):
        """æ‰“é–‹æ‰€æœ‰è‚¡ç¥¨çš„ Beta é é¢ä¸¦ç­‰å¾… CAPTCHA é€šéï¼ˆç„¡æ™‚é–“é™åˆ¶ï¼‰"""
        pages_and_contexts = []

        for i, stock in enumerate(self.stocks):
            print(f"\n{'=' * 50}")
            print(f"æ‰“é–‹ {stock} çš„é é¢ ({i + 1}/{len(self.stocks)})")
            print(f"{'=' * 50}")

            try:
                # å‰µå»ºæ–°çš„ context
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1280, "height": 960},
                    java_script_enabled=True,
                    locale='zh-TW',
                    timezone_id='Asia/Taipei',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )

                # æ³¨å…¥ååµæ¸¬è…³æœ¬
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-TW', 'zh', 'en-US', 'en']
                    });
                """)

                page = await context.new_page()

                # ğŸ”¥ ç§»é™¤ yfinanceï¼Œæ”¹ç”¨ stock_exchanges
                exchange_name = self.stock_exchanges.get(stock, 'NYSE')  # é è¨­ NYSE

                stock_symbol = ''.join(['.' if char == '-' else char for char in stock]) if '-' in stock else stock

                # ğŸ”¥ ç›´æ¥ä½¿ç”¨ exchangeName
                URL = f'https://tw.tradingview.com/symbols/{exchange_name}-{stock_symbol}/'

                # è¨ªå•é é¢
                await asyncio.sleep(random.uniform(2, 4))
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)
                await asyncio.sleep(random.uniform(2, 3))

                # ğŸ”¥ æª¢æŸ¥ CAPTCHAï¼ˆç„¡é™ç­‰å¾…ï¼‰
                await self._wait_for_captcha_resolution(stock, page)

                # ä¿å­˜é é¢å’Œ context
                pages_and_contexts.append((stock, page, context))
                print(f"âœ“ {stock} é é¢å·²å°±ç·’")

                # æ¯å€‹é é¢ä¹‹é–“å»¶é²
                if i < len(self.stocks) - 1:
                    await asyncio.sleep(random.uniform(1, 2))

            except Exception as e:
                print(f"âŒ {stock} é é¢æ‰“é–‹å¤±æ•—: {e}")
                if context:
                    try:
                        await context.close()
                    except:
                        pass

        return pages_and_contexts

    async def _wait_for_captcha_resolution(self, stock, page):
        """ç­‰å¾… CAPTCHA è¢«è§£æ±ºï¼ˆç„¡æ™‚é–“é™åˆ¶ï¼‰+ å¼·åˆ¶ç½®ä¸­ reCAPTCHA"""

        # ğŸ”¥ æ–¹æ¡ˆ 1ï¼šæ³¨å…¥ CSS å¼·åˆ¶ç½®ä¸­ reCAPTCHA çš„æ‰€æœ‰å…ƒç´ 
        try:
            await page.add_style_tag(content="""
                /* ç½®ä¸­ reCAPTCHA çš„ä¸»å®¹å™¨ */
                .g-recaptcha {
                    display: flex !important;
                    justify-content: center !important;
                    align-items: center !important;
                    position: fixed !important;
                    top: 50% !important;
                    left: 50% !important;
                    transform: translate(-50%, -50%) !important;
                    z-index: 999999 !important;
                }

                /* ç½®ä¸­æ‰€æœ‰ reCAPTCHA çš„ iframe */
                iframe[src*="recaptcha"],
                iframe[src*="google.com/recaptcha"],
                iframe[title*="reCAPTCHA"] {
                    position: fixed !important;
                    top: 50% !important;
                    left: 50% !important;
                    transform: translate(-50%, -50%) !important;
                    z-index: 999999 !important;
                }

                /* éš±è—èƒŒæ™¯çš„å¹²æ“¾å…ƒç´  */
                .tv-captcha-page__message-wrap {
                    position: relative !important;
                }

                /* ç¢ºä¿è¡¨å–®ä¸æœƒå½±éŸ¿ CAPTCHA ä½ç½® */
                #frmCaptcha {
                    display: flex !important;
                    flex-direction: column !important;
                    align-items: center !important;
                    justify-content: center !important;
                }

                /* éš±è—æˆ–èª¿æ•´å…¶ä»–å…§å®¹ */
                .tv-text h1,
                .tv-text p {
                    position: relative !important;
                    z-index: 1 !important;
                }
            """)
            print(f"   âœ“ å·²æ³¨å…¥ reCAPTCHA ç½®ä¸­ CSS")
        except Exception as e:
            print(f"   âš ï¸ æ³¨å…¥ CSS å¤±æ•—: {e}")

        # ğŸ”¥ æ–¹æ¡ˆ 2ï¼šç­‰å¾… reCAPTCHA è¼‰å…¥å¾Œï¼Œç”¨ JavaScript å¼·åˆ¶ç§»å‹•
        try:
            await page.evaluate("""
                async () => {
                    // ç­‰å¾… reCAPTCHA iframe å®Œå…¨è¼‰å…¥
                    const waitForRecaptcha = () => {
                        return new Promise((resolve) => {
                            const checkInterval = setInterval(() => {
                                // å°‹æ‰¾æ‰€æœ‰ reCAPTCHA iframe
                                const recaptchaIframes = document.querySelectorAll('iframe[src*="recaptcha"]');

                                if (recaptchaIframes.length > 0) {
                                    clearInterval(checkInterval);
                                    resolve(recaptchaIframes);
                                }
                            }, 100);

                            // 10 ç§’å¾Œè¶…æ™‚
                            setTimeout(() => {
                                clearInterval(checkInterval);
                                resolve([]);
                            }, 10000);
                        });
                    };

                    const iframes = await waitForRecaptcha();

                    if (iframes.length > 0) {
                        console.log('æ‰¾åˆ°', iframes.length, 'å€‹ reCAPTCHA iframe');

                        iframes.forEach((iframe, index) => {
                            // å¼·åˆ¶è¨­å®š iframe ä½ç½®
                            iframe.style.cssText = `
                                position: fixed !important;
                                top: 50% !important;
                                left: 50% !important;
                                transform: translate(-50%, -50%) !important;
                                z-index: ${999999 + index} !important;
                                margin: 0 !important;
                            `;

                            console.log('âœ“ iframe', index, 'å·²ç½®ä¸­');
                        });

                        // ä¹Ÿè™•ç† .g-recaptcha å®¹å™¨
                        const recaptchaDiv = document.querySelector('.g-recaptcha');
                        if (recaptchaDiv) {
                            recaptchaDiv.style.cssText = `
                                position: fixed !important;
                                top: 50% !important;
                                left: 50% !important;
                                transform: translate(-50%, -50%) !important;
                                z-index: 999998 !important;
                                display: flex !important;
                                justify-content: center !important;
                                align-items: center !important;
                            `;
                            console.log('âœ“ .g-recaptcha å®¹å™¨å·²ç½®ä¸­');
                        }

                        // èª¿æ•´é é¢èƒŒæ™¯ï¼Œè®“ CAPTCHA æ›´æ˜é¡¯
                        const messageWrap = document.querySelector('.tv-captcha-page__message-wrap');
                        if (messageWrap) {
                            messageWrap.style.opacity = '0.3';
                        }
                    }
                }
            """)
            print(f"   âœ“ å·²åŸ·è¡Œ reCAPTCHA ç½®ä¸­è…³æœ¬")
        except Exception as e:
            print(f"   âš ï¸ åŸ·è¡Œç½®ä¸­è…³æœ¬å¤±æ•—: {e}")

        # ğŸ”¥ æ–¹æ¡ˆ 3ï¼šæŒçºŒç›£æ§ä¸¦èª¿æ•´ï¼ˆé˜²æ­¢ reCAPTCHA é‡æ–°è¼‰å…¥å¾Œä½ç½®è·‘æ‰ï¼‰
        try:
            await page.evaluate("""
                () => {
                    // å»ºç«‹ MutationObserver ç›£æ§ DOM è®ŠåŒ–
                    const observer = new MutationObserver(() => {
                        const iframes = document.querySelectorAll('iframe[src*="recaptcha"]');
                        iframes.forEach((iframe) => {
                            if (iframe.style.position !== 'fixed') {
                                iframe.style.cssText = `
                                    position: fixed !important;
                                    top: 50% !important;
                                    left: 50% !important;
                                    transform: translate(-50%, -50%) !important;
                                    z-index: 999999 !important;
                                `;
                            }
                        });
                    });

                    observer.observe(document.body, {
                        childList: true,
                        subtree: true
                    });

                    // 30 ç§’å¾Œåœæ­¢ç›£æ§
                    setTimeout(() => observer.disconnect(), 30000);
                }
            """)
            print(f"   âœ“ å·²å•Ÿå‹• reCAPTCHA æŒçºŒç›£æ§")
        except Exception as e:
            print(f"   âš ï¸ å•Ÿå‹•ç›£æ§å¤±æ•—: {e}")

        # ç­‰å¾…ä¸€ä¸‹è®“è…³æœ¬åŸ·è¡Œ
        await asyncio.sleep(2)

        captcha_visible = await self._check_captcha_visible(page)

        if captcha_visible:
            print("\n" + "ğŸ”´" * 30)
            print(f"âš ï¸  {stock} åµæ¸¬åˆ° CAPTCHA é©—è­‰ï¼")
            print("âš ï¸  reCAPTCHA æ‡‰è©²å·²ç¶“ç§»åˆ°ç•«é¢æ­£ä¸­é–“")
            print("âš ï¸  è«‹æ‰‹å‹•å®Œæˆé©—è­‰")
            print("âš ï¸  å®Œæˆå¾Œå°‡è‡ªå‹•ç¹¼çºŒ...")
            print("ğŸ”´" * 30 + "\n")

            # ğŸ”¥ ç„¡é™ç­‰å¾…ç›´åˆ° CAPTCHA æ¶ˆå¤±
            check_count = 0
            while True:
                await asyncio.sleep(5)
                check_count += 1

                still_visible = await self._check_captcha_visible(page)

                if not still_visible:
                    print(f"âœ… {stock} CAPTCHA å·²é€šéï¼")
                    break

                # æ¯ 20 ç§’æç¤ºä¸€æ¬¡
                if check_count % 4 == 0:
                    print(f"   {stock} ç­‰å¾…ä¸­... (å·²ç­‰å¾… {check_count * 5} ç§’)")

                    # ğŸ”¥ æ¯ 20 ç§’é‡æ–°æª¢æŸ¥ä¸¦èª¿æ•´ä½ç½®ï¼ˆä»¥é˜²è¬ä¸€ï¼‰
                    try:
                        await page.evaluate("""
                            () => {
                                const iframes = document.querySelectorAll('iframe[src*="recaptcha"]');
                                iframes.forEach((iframe) => {
                                    iframe.style.cssText = `
                                        position: fixed !important;
                                        top: 50% !important;
                                        left: 50% !important;
                                        transform: translate(-50%, -50%) !important;
                                        z-index: 999999 !important;
                                    `;
                                });
                            }
                        """)
                    except:
                        pass

            # CAPTCHA é€šéå¾Œé¡å¤–ç­‰å¾…
            await asyncio.sleep(random.uniform(2, 4))

    async def _check_captcha_visible(self, page):
        """æª¢æŸ¥ CAPTCHA æ˜¯å¦å¯è¦‹"""
        try:
            # æª¢æŸ¥ iframe
            captcha_frame = await page.query_selector('iframe[src*="captcha"], iframe[title*="reCAPTCHA"]')
            if captcha_frame:
                is_visible = await captcha_frame.is_visible()
                if is_visible:
                    return True

            # æª¢æŸ¥å…¶ä»–å…ƒç´ 
            captcha_element = await page.query_selector('[class*="captcha"], [id*="captcha"], .g-recaptcha')
            if captcha_element:
                is_visible = await captcha_element.is_visible()
                if is_visible:
                    return True

            return False
        except:
            return False

    async def _extract_beta_from_page(self, stock, page):
        """å¾å·²è¼‰å…¥çš„é é¢ä¸­æå– Beta å€¼"""
        try:
            # æ¨¡æ“¬äººé¡ç€è¦½è¡Œç‚º
            scroll_positions = [300, 600, 400, 100, 0]
            for pos in scroll_positions:
                await page.evaluate(f'window.scrollTo(0, {pos})')
                await asyncio.sleep(random.uniform(0.3, 0.6))

            # ç²å–å…§å®¹
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')

            # è§£æ Beta å€¼ï¼ˆä½¿ç”¨åŸæœ‰é‚è¼¯ï¼‰
            beta_section = None
            all_wrappers = soup.find_all('div', class_='wrapper-QCJM7wcY')

            for wrapper in all_wrappers:
                parent = wrapper.find_parent()
                if parent and 'beta' in parent.get_text().lower():
                    beta_section = wrapper
                    break

            if beta_section:
                value_div = beta_section.find('div', class_='value-QCJM7wcY')
                if value_div:
                    beta_text = value_div.get_text(strip=True)
                    try:
                        return float(beta_text)
                    except ValueError:
                        pass

            # å‚™ç”¨æ–¹æ¡ˆ
            for wrapper in all_wrappers:
                value_div = wrapper.find('div', class_='value-QCJM7wcY')
                if value_div:
                    value_text = value_div.get_text(strip=True)
                    try:
                        value_float = float(value_text)
                        if 0.1 <= value_float <= 5.0:
                            nearby_text = wrapper.find_parent().get_text().lower()
                            if 'beta' in nearby_text:
                                return value_float
                    except ValueError:
                        continue

            return None

        except Exception as e:
            print(f"æå– Beta å€¼å¤±æ•—: {e}")
            return None

    async def fetch_barchart_data(self, stock, semaphore):
        """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„æ•¸æ“šï¼ˆBarchart Volatilityï¼‰"""
        async with semaphore:
            context = None  # ğŸ”¥ åˆå§‹åŒ–
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    java_script_enabled=True,
                )
                # ğŸ”¥ è¿½è¹¤ context
                async with self.contexts_lock:
                    self.contexts.append(context)
                try:
                    page = await context.new_page()
                    html_content = await self.get_barchart_html(stock, page)
                    return {stock: html_content}
                finally:
                    await context.close()
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
            except Exception as e:
                # ç¢ºä¿ context è¢«é—œé–‰
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    # ğŸ”¥ ç§»é™¤è¿½è¹¤
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {stock: {"error": str(e)}}

    async def get_barchart_html(self, stock, page, retries=3):
        """æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„Barcharté é¢ä¸¦å›å‚³å®Œæ•´HTML"""
        URL = f'https://www.barchart.com/stocks/quotes/{stock}/volatility-charts'
        attempt = 0

        while attempt < retries:
            try:
                print(f"æ­£åœ¨å˜—è©¦æŠ“å– {stock} çš„Barcharté é¢ (ç¬¬ {attempt + 1} æ¬¡)...")

                await asyncio.sleep(random.uniform(2, 5))
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)

                # ç­‰å¾…é é¢è¼‰å…¥
                await asyncio.sleep(3)

                # ç²å–å®Œæ•´HTMLå…§å®¹
                content = await page.content()

                # print(f"âœ“ æˆåŠŸç²å– {stock} çš„HTMLï¼Œé•·åº¦: {len(content)}")
                bs = BeautifulSoup(content, 'html.parser')

                div = bs.find('div', {'class':'bc-datatable-toolbar bc-options-toolbar volatility'})
                # print(div)
                return div.text.replace('\xa0', ' ')
                # return content

            except Exception as e:
                print(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                attempt += 1
                if attempt < retries:
                    await asyncio.sleep(random.uniform(5, 10))

        return None

    async def run_barchart(self):
        """åŸ·è¡ŒBarchartæ•¸æ“šæŠ“å–"""
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_barchart_data(stock, semaphore) for stock in self.stocks]
            result = await asyncio.gather(*tasks)
            return result
        finally:
            await self.cleanup()

    # åœ¨ StockScraper é¡åˆ¥ä¸­ï¼ŒåŠ åœ¨ run_barchart() æ–¹æ³•ä¹‹å¾Œ

    async def fetch_earnings_date_data(self, stock, semaphore):
        """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„è²¡å ±æ—¥æœŸï¼ˆearningshubï¼‰"""
        async with semaphore:
            context = None
            try:
                context = await self.browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    java_script_enabled=True,
                    locale='zh-TW',
                    timezone_id='Asia/Taipei',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )

                # æ³¨å…¥ååµæ¸¬è…³æœ¬
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });

                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };

                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });

                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-TW', 'zh', 'en-US', 'en']
                    });
                """)

                async with self.contexts_lock:
                    self.contexts.append(context)

                try:
                    page = await context.new_page()
                    earnings_data = await self.get_earnings_date_earningshub(stock, page)
                    return {stock: earnings_data}
                finally:
                    await context.close()
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)

            except Exception as e:
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                    async with self.contexts_lock:
                        if context in self.contexts:
                            self.contexts.remove(context)
                return {stock: None}

    async def get_earnings_date_earningshub(self, stock, page, retries=3):
        """
        å¾ earningshub.com çˆ¬å–è²¡å ±æ—¥æœŸ - æ”¹é€²ç‰ˆ

        ç­–ç•¥ï¼š
        1. æ‰¾åˆ°æ‰€æœ‰åŒ…å« "Earnings" çš„å€å¡Š
        2. æå–æ‰€æœ‰æ—¥æœŸ
        3. éæ¿¾å‡ºæœªä¾†æ—¥æœŸ
        4. é¸æ“‡æœ€è¿‘çš„ä¸€å€‹

        Returns:
            dict: {'earnings_date': '2026å¹´2æœˆ19æ—¥ é€±å›› ä¸Šåˆ5:00', 'status': 'ESTIMATE'}
            None: æ‰¾ä¸åˆ°æœªä¾†è²¡å ±
        """
        from bs4 import BeautifulSoup
        import random
        from datetime import datetime
        import re

        # è‚¡ç¥¨ä»£ç¢¼è½‰æ›
        original_stock = stock
        if '-' in stock:
            stock = ''.join(['.' if char == '-' else char for char in stock])
            print(f"   è‚¡ç¥¨ä»£ç¢¼è½‰æ›: {original_stock} â†’ {stock}")

        URL = f'https://earningshub.com/quote/{stock}'
        attempt = 0

        while attempt < retries:
            try:
                print(f"æ­£åœ¨æŠ“å– {original_stock} çš„è²¡å ±æ—¥æœŸ (ç¬¬ {attempt + 1} æ¬¡)...")

                # éš¨æ©Ÿå»¶é²
                await asyncio.sleep(random.uniform(2, 4))

                # å‰å¾€é é¢
                await page.goto(URL, wait_until='domcontentloaded', timeout=60000)

                # æ¨¡æ“¬äººé¡ç€è¦½è¡Œç‚º
                await asyncio.sleep(random.uniform(1, 2))
                await page.evaluate('window.scrollTo(0, 200)')
                await asyncio.sleep(random.uniform(0.5, 1))

                # ç­‰å¾…é—œéµå…ƒç´ è¼‰å…¥
                try:
                    await page.wait_for_selector('div.MuiAlert-root', timeout=10000)
                    await asyncio.sleep(2)
                except Exception:
                    print(f"   ç­‰å¾…å…ƒç´ è¶…æ™‚ï¼Œç¹¼çºŒå˜—è©¦è§£æ...")

                # ç²å–é é¢å…§å®¹
                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')

                # ===== æ­¥é©Ÿ 1: æ‰¾åˆ°æ‰€æœ‰ MuiAlert å€å¡Š =====
                all_alerts = soup.find_all('div', class_='MuiAlert-root')
                print(f"   æ‰¾åˆ° {len(all_alerts)} å€‹ Alert å€å¡Š")

                all_earnings_data = []  # å„²å­˜æ‰€æœ‰æ‰¾åˆ°çš„è²¡å ±è³‡è¨Š

                # ===== æ­¥é©Ÿ 2: éæ­·æ‰€æœ‰å€å¡Šï¼Œæå–æ—¥æœŸ =====
                for alert_index, alert in enumerate(all_alerts, 1):
                    alert_text = alert.get_text()

                    # ğŸ”¥ é—œéµéæ¿¾ï¼šå¿…é ˆåŒ…å« "Earnings" å’Œå­£åº¦æ¨™è¨˜
                    if 'Earnings' not in alert_text:
                        continue

                    has_quarter = any(q in alert_text for q in ['Q1 ', 'Q2 ', 'Q3 ', 'Q4 '])
                    if not has_quarter:
                        continue

                    print(f"   Alert {alert_index}: æ‰¾åˆ° Earnings å€å¡Š")

                    # å°‹æ‰¾æ—¥æœŸ span
                    date_span = alert.find('span', class_='MuiTypography-caption')

                    if not date_span:
                        print(f"      âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸ span")
                        continue

                    # æå–æ—¥æœŸæ–‡å­—
                    date_text = date_span.get_text(strip=True)

                    # ç§»é™¤æ¨™ç±¤ï¼ˆESTIMATE / CONFIRMEDï¼‰
                    status = None
                    inner_box = date_span.find('span', class_='MuiBox-root')
                    if inner_box:
                        status = inner_box.get_text(strip=True)
                        date_text = date_text.replace(status, '').strip()

                    # é©—è­‰æ—¥æœŸæ ¼å¼ï¼ˆå¿…é ˆåŒ…å«ã€Œå¹´æœˆæ—¥ã€ï¼‰
                    if 'å¹´' not in date_text or 'æœˆ' not in date_text or 'æ—¥' not in date_text:
                        print(f"      âš ï¸ æ—¥æœŸæ ¼å¼ä¸æ­£ç¢º: {date_text}")
                        continue

                    print(f"      âœ“ åŸå§‹æ—¥æœŸ: {date_text}")
                    if status:
                        print(f"      âœ“ ç‹€æ…‹: {status}")

                    # è§£ææ—¥æœŸ
                    try:
                        parsed_date = self._parse_chinese_date(date_text)
                        print(f"      âœ“ è§£æå¾Œ: {parsed_date}")

                        # å„²å­˜è³‡è¨Š
                        all_earnings_data.append({
                            'date': parsed_date,
                            'date_text': date_text,
                            'status': status or 'CONFIRMED',
                            'alert_type': self._get_alert_color(alert),
                            'raw_text': alert_text[:100]  # å‰ 100 å­—ç¬¦ä¾›èª¿è©¦
                        })

                    except Exception as parse_error:
                        print(f"      âŒ æ—¥æœŸè§£æå¤±æ•—: {parse_error}")
                        continue

                # ===== æ­¥é©Ÿ 3: éæ¿¾æœªä¾†æ—¥æœŸ =====
                if not all_earnings_data:
                    print(f"   âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è²¡å ±æ—¥æœŸ")
                    attempt += 1
                    if attempt >= retries:
                        return None
                    continue

                print(f"\n   ğŸ“Š æ‰¾åˆ° {len(all_earnings_data)} å€‹è²¡å ±æ—¥æœŸï¼š")
                for i, data in enumerate(all_earnings_data, 1):
                    print(f"      {i}. {data['date_text']} ({data['status']})")

                # å–å¾—ç•¶å‰æ™‚é–“ï¼ˆå°åŒ—æ™‚å€ï¼‰
                from datetime import timezone, timedelta
                taipei_tz = timezone(timedelta(hours=8))
                now = datetime.now(taipei_tz)

                # éæ¿¾æœªä¾†æ—¥æœŸ
                future_dates = [
                    d for d in all_earnings_data
                    if d['date'] > now
                ]

                print(f"\n   ğŸ”® æœªä¾†è²¡å ±: {len(future_dates)} å€‹")

                if not future_dates:
                    print(f"   âš ï¸ æ²’æœ‰æ‰¾åˆ°æœªä¾†çš„è²¡å ±æ—¥æœŸ")
                    return None

                # ===== æ­¥é©Ÿ 4: é¸æ“‡æœ€è¿‘çš„æœªä¾†æ—¥æœŸ =====
                next_earnings = min(future_dates, key=lambda x: x['date'])

                print(f"\n   âœ… æœ€è¿‘çš„æœªä¾†è²¡å ±:")
                print(f"      æ—¥æœŸ: {next_earnings['date_text']}")
                print(f"      ç‹€æ…‹: {next_earnings['status']}")
                print(f"      è·ä»Š: {(next_earnings['date'] - now).days} å¤©")

                return {
                    'earnings_date': next_earnings['date_text'],
                    'status': next_earnings['status'],
                    'source': 'earningshub'
                }

            except Exception as e:
                attempt += 1
                print(f"   âŒ ç¬¬ {attempt} æ¬¡å˜—è©¦å¤±æ•—: {e}")

                if attempt >= retries:
                    print(f"   âŒ {original_stock} åœ¨ {retries} æ¬¡å˜—è©¦å¾Œä»ç„¡æ³•ç²å–è²¡å ±æ—¥æœŸ")
                    return None

                wait_time = random.uniform(5, 10)
                print(f"   ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                await asyncio.sleep(wait_time)

        return None

    def _parse_chinese_date(self, date_str):
        """
        è§£æä¸­æ–‡æ—¥æœŸæ ¼å¼

        ç¯„ä¾‹ï¼š
        - "2026å¹´2æœˆ19æ—¥ é€±å›› ä¸Šåˆ5:00"
        - "2026å¹´2æœˆ19æ—¥ é€±å›› ä¸‹åˆ9:00"

        Returns:
            datetime: å¸¶æ™‚å€çš„ datetime ç‰©ä»¶ï¼ˆå°åŒ—æ™‚å€ï¼‰
        """
        from datetime import datetime, timezone, timedelta
        import re

        # æ­£å‰‡è¡¨é”å¼ï¼š2026å¹´2æœˆ19æ—¥ é€±å›› ä¸Šåˆ5:00
        pattern = r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥.*?(ä¸Šåˆ|ä¸‹åˆ)(\d{1,2}):(\d{2})'
        match = re.search(pattern, date_str)

        if not match:
            raise ValueError(f"ç„¡æ³•è§£ææ—¥æœŸæ ¼å¼: {date_str}")

        year = int(match.group(1))
        month = int(match.group(2))
        day = int(match.group(3))
        am_pm = match.group(4)
        hour = int(match.group(5))
        minute = int(match.group(6))

        # è½‰æ›ç‚º 24 å°æ™‚åˆ¶
        if am_pm == 'ä¸‹åˆ' and hour != 12:
            hour += 12
        elif am_pm == 'ä¸Šåˆ' and hour == 12:
            hour = 0

        # å»ºç«‹å¸¶æ™‚å€çš„ datetimeï¼ˆå°åŒ—æ™‚å€ UTC+8ï¼‰
        taipei_tz = timezone(timedelta(hours=8))
        dt = datetime(year, month, day, hour, minute, tzinfo=taipei_tz)

        return dt

    def _get_alert_color(self, alert):
        """
        åˆ¤æ–· Alert çš„é¡è‰²é¡å‹

        Returns:
            str: 'info' (è—è‰²), 'warning' (é»ƒè‰²), 'error' (ç´…è‰²)
        """
        class_str = alert.get('class', [])

        if 'MuiAlert-colorInfo' in class_str:
            return 'info'
        elif 'MuiAlert-colorWarning' in class_str:
            return 'warning'
        elif 'MuiAlert-colorError' in class_str:
            return 'error'
        else:
            return 'unknown'

    async def run_earnings_dates(self):
        """æ‰¹æ¬¡åŸ·è¡Œè²¡å ±æ—¥æœŸæŠ“å–"""
        await self.setup_browser()
        semaphore = asyncio.Semaphore(self.max_concurrent)
        try:
            tasks = [self.fetch_earnings_date_data(stock, semaphore) for stock in self.stocks]
            result = await asyncio.gather(*tasks)
            return result
        finally:
            await self.cleanup()

    async def fetch_option_chain_data(self, stock, semaphore):
        """æŠ“å–å–®ä¸€è‚¡ç¥¨çš„é¸æ“‡æ¬Šéˆæ•¸æ“š"""
        async with semaphore:
            try:
                # æª¢æŸ¥ Schwab API æ˜¯å¦å¯ç”¨
                if not self.schwab_available:
                    return {stock: {"error": "Schwab API é…ç½®æœªå®Œæ•´è¨­å®š"}}

                # ä½¿ç”¨ schwabdev å®¢æˆ¶ç«¯
                option_data = await asyncio.to_thread(
                    self._get_option_chain_sync, stock
                )
                return {stock: option_data}
            except Exception as e:
                return {stock: {"error": str(e)}}

    def _get_option_chain_sync(self, stock):
        """åŒæ­¥ç²å–é¸æ“‡æ¬Šéˆæ•¸æ“š - ä½¿ç”¨é‡ç”¨çš„ Client"""

        # ğŸ”¥ ç¢ºä¿ Client å·²åˆå§‹åŒ–
        if self.schwab_client is None:
            self.initialize_schwab_client()

        try:
            # ğŸ”¥ ä½¿ç”¨é‡ç”¨çš„ Client
            response = self.schwab_client.option_chains(stock)

            # å˜—è©¦è§£æ JSON
            try:
                data = response.json()
            except json.JSONDecodeError as e:
                response_text = response.text if hasattr(response, 'text') else str(response)
                raise ValueError(f"ç„¡æ³•è§£æ API å›æ‡‰: {response_text[:200]}")

            # æª¢æŸ¥æ˜¯å¦æœ‰ Token éŒ¯èª¤
            if isinstance(data, dict):
                if 'error' in data:
                    error_type = data.get('error', '')
                    error_desc = data.get('error_description', '')

                    if 'refresh_token_authentication_error' in error_desc or \
                            'refresh_token_authentication_error' in error_type or \
                            'unsupported_token_type' in error_type:

                        print(f"âŒ Token èªè­‰å¤±æ•—: {error_desc}")
                        raise TokenExpiredException(
                            f"Refresh Token å·²å¤±æ•ˆæˆ–éæœŸ\n"
                            f"éŒ¯èª¤é¡å‹: {error_type}\n"
                            f"éŒ¯èª¤æè¿°: {error_desc}\n\n"
                            f"è«‹é‡æ–°å•Ÿå‹•ç¨‹å¼å®Œæˆèªè­‰æµç¨‹ã€‚"
                        )
                    else:
                        raise ValueError(f"API éŒ¯èª¤: {error_type} - {error_desc}")

            return data

        except TokenExpiredException:
            raise

        except Exception as e:
            error_str = str(e).lower()
            if 'refresh_token' in error_str or ('token' in error_str and 'authentication' in error_str):
                raise TokenExpiredException(
                    f"Token èªè­‰å¤±æ•—: {str(e)}\n\n"
                    f"è«‹é‡æ–°å•Ÿå‹•ç¨‹å¼å®Œæˆèªè­‰æµç¨‹ã€‚"
                )
            else:
                raise e

    async def run_option_chains(self):
        """æ‰¹æ¬¡åŸ·è¡Œé¸æ“‡æ¬ŠéˆæŠ“å– - ä½¿ç”¨ Schwab APIï¼ˆå„ªåŒ–ç‰ˆï¼‰"""

        # ğŸ”¥ åˆå§‹åŒ– Clientï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰
        try:
            self.initialize_schwab_client()
        except Exception as e:
            print(f"âŒ Schwab Client åˆå§‹åŒ–å¤±æ•—: {e}")
            return []

        semaphore = asyncio.Semaphore(self.max_concurrent)

        try:
            tasks = [
                self.fetch_option_chain_data(stock, semaphore)
                for stock in self.stocks
            ]
            result = await asyncio.gather(*tasks)
            return result

        except Exception as e:
            print(f"âŒ é¸æ“‡æ¬ŠéˆæŠ“å–å¤±æ•—: {e}")
            return []
